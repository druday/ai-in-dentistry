{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "02f4f2bb-3182-482b-ab74-fa6210a15285",
   "metadata": {},
   "source": [
    "\"\"\"(\"Artificial Intelligence\"[Mesh] OR \"Generative Artificial Intelligence\"[Mesh] OR \"artificial intelligence\" OR \"informatics\" OR \"machine learning\" OR \"deep learning\" OR \"neural network*\" OR \"AI\" OR \"large language\" OR \"chatgpt\") AND (\"Dentistry\"[Mesh] OR \"Evidence-Based Dentistry\"[Mesh] OR \"Mouth\"[Mesh] OR \"Oral Medicine\"[Mesh] OR \"dental[ti]\" OR \"oral\"[ti] OR \"dentistry\"[ti] OR \"mouth\"[ti] OR \"teeth\"[ti] OR \"tooth\"[ti] OR \"buccal\"[ti] OR \"pharynx\"[ti] OR \"pharyngeal\"[ti] OR \"tongue\"[ti] OR \"maxillary\"[ti] OR \"mandibular\"[ti])\"\"\"\n",
    "\n",
    "Informatics: 533\n",
    "\"\"\"(\"informatic*\"[tiab] ) AND (\"Dentistry\"[Mesh] OR \"Evidence-Based Dentistry\"[Mesh] OR \"Mouth\"[Mesh] OR \"Oral Medicine\"[Mesh] OR \"dental\"[tiab] OR \"oral\"[tiab] OR \"dentistry\"[tiab] OR \"mouth\"[tiab] OR \"teeth\"[tiab] OR \"tooth\"[tiab] OR \"buccal\"[tiab] OR \"pharynx\"[tiab] OR \"pharyngeal\"[tiab] OR \"tongue\"[tiab] OR \"maxillary\"[tiab] OR \"mandibular\"[tiab])\"\"\"\n",
    "\n",
    "LLMs:\n",
    "\"\"\"(\"large language\"[tiab] OR \"chatgpt\"[tiab] OR \"Generative Artificial Intelligence\"[tiab] OR \"LLM\"[tiab] OR \"LLMs\"[tiab]) AND (\"Dentistry\"[Mesh] OR \"Evidence-Based Dentistry\"[Mesh] OR \"Mouth\"[Mesh] OR \"Oral Medicine\"[Mesh] OR \"dental\"[tiab] OR \"oral\"[tiab] OR \"dentistry\"[tiab] OR \"mouth\"[tiab] OR \"teeth\"[tiab] OR \"tooth\"[tiab] OR \"buccal\"[tiab] OR \"pharynx\"[tiab] OR \"pharyngeal\"[tiab] OR \"tongue\"[tiab] OR \"maxillary\"[tiab] OR \"mandibular\"[tiab])\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "766b2ae8-da9f-49bd-8b95-2dee6b64aaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of publications that contain the term ((\"Artificial Intelligence\"[Mesh] OR \"Generative Artificial Intelligence\"[Mesh] OR \"artificial intelligence\" OR \"informatics\" OR \"machine learning\" OR \"deep learning\" OR \"neural network*\" OR \"AI\" OR \"large language\" OR \"chatgpt\") AND (\"Dentistry\"[Mesh] OR \"Evidence-Based Dentistry\"[Mesh] OR \"Mouth\"[Mesh] OR \"Oral Medicine\"[Mesh] OR \"dental[ti]\" OR \"oral\"[ti] OR \"dentistry\"[ti] OR \"mouth\"[ti] OR \"teeth\"[ti] OR \"tooth\"[ti] OR \"buccal\"[ti] OR \"pharynx\"[ti] OR \"pharyngeal\"[ti] OR \"tongue\"[ti] OR \"maxillary\"[ti] OR \"mandibular\"[ti])) AND ((\"1930/01/01\"[Date - Publication] : \"2020/01/01\"[Date - Publication])): 6174\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 62/62 [00:52<00:00,  1.19it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nxviz\n",
    "import difflib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "from dateutil import parser\n",
    "from iso3166 import countries\n",
    "import pycountry_convert as pc\n",
    "import country_converter as coco\n",
    "from itertools import combinations\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "\n",
    "# Change this email to your email address\n",
    "Entrez.email = \"pratapsingh@1102@gmail.com\"\n",
    "\n",
    "keyword = \"\"\"((\"Artificial Intelligence\"[Mesh] OR \"Generative Artificial Intelligence\"[Mesh] OR \"artificial intelligence\" OR \"informatics\" OR \"machine learning\" OR \"deep learning\" OR \"neural network*\" OR \"AI\" OR \"large language\" OR \"chatgpt\") AND (\"Dentistry\"[Mesh] OR \"Evidence-Based Dentistry\"[Mesh] OR \"Mouth\"[Mesh] OR \"Oral Medicine\"[Mesh] OR \"dental[ti]\" OR \"oral\"[ti] OR \"dentistry\"[ti] OR \"mouth\"[ti] OR \"teeth\"[ti] OR \"tooth\"[ti] OR \"buccal\"[ti] OR \"pharynx\"[ti] OR \"pharyngeal\"[ti] OR \"tongue\"[ti] OR \"maxillary\"[ti] OR \"mandibular\"[ti])) AND ((\"1930/01/01\"[Date - Publication] : \"2020/01/01\"[Date - Publication]))\"\"\"\n",
    "\n",
    "result = Entrez.read(Entrez.esearch(db=\"pubmed\", retmax=10, term=keyword))\n",
    "print(\n",
    "    \"Total number of publications that contain the term {}: {}\".format(\n",
    "        keyword, result[\"Count\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fetch all ids\n",
    "MAX_COUNT = result[\"Count\"]\n",
    "result = Entrez.read(\n",
    "    Entrez.esearch(db=\"pubmed\", retmax=result[\"Count\"], term=keyword)\n",
    ")\n",
    "\n",
    "ids = result[\"IdList\"]\n",
    "\n",
    "batch_size = 100\n",
    "batches = [ids[x: x + 100] for x in range(0, len(ids), batch_size)]\n",
    "\n",
    "record_list = []\n",
    "for batch in tqdm(batches):\n",
    "    h = Entrez.efetch(db=\"pubmed\", id=batch, rettype=\"medline\", retmode=\"text\")\n",
    "    records = Medline.parse(h)\n",
    "    record_list.extend(list(records))\n",
    "print(\"Complete.\")\n",
    "\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "publication_data = pd.DataFrame(record_list)\n",
    "publication_data. rename(columns = {'AB':'Abstract', 'CI':'Copyright Information',\n",
    "                     'AD':'Affiliation', 'IRAD':'Investigator Affiliation',\n",
    "                     'AU':'Author', 'FAU':'Full Author',\n",
    "                      'COIS':'Conflict of Interest Statement', 'CRDT':'Create Date',\n",
    "                      'DEP':'Date of Electronic Publication', 'DP':'Date of Publication',\n",
    "                      'EN':'Edition', 'ED':'Editor',\n",
    "                      'GN':'General Note', 'FIR':'Full Investigator Name',\n",
    "                      'JT':'Journal Title', 'RF':'Number of References',\n",
    "                      'PL':'Place of Publication', 'PST':'Publication Status',\n",
    "                      'PT':'Publication Type', 'PUBM':'Publication Model',\n",
    "                      'NM':'Substance Name', 'TI':'Title', 'LID':'Location Identifier',\n",
    "                      'PMID':'PubMed Unique Identifier', 'OWN':'Owner', 'STAT':'Status', 'LR':'Date Last Revised', 'IS':'ISSN', \n",
    "                      'VI':'Volume', 'IP':'Issue', 'PG':'Pagination',\n",
    "                      'LA':'Language', 'TA': 'Journal Title Abbreviation', 'JID': 'NLM Unique ID', \n",
    "                      'PMC':'PubMed Central Identifier', 'OTO':'Other Term Owner','OT':'Other Term', 'EDAT':'Entrez Date', \n",
    "                      'MHDA':'MeSH Date', 'PHST':'Publication History Status', 'AID':'Article Identifier', 'SO':'Source', \n",
    "                      'AUID':'Author Identifier', 'GR':'Grant Number', 'SB':'Subset', 'SI': 'Secondary Source ID',\n",
    "                      'DCOM':'Date Completed', 'RN': 'Registry Number/EC Number', 'MH': 'MeSH Terms', 'BTI':'Book Title', \n",
    "                      'PMCR':'PubMed Central Release', 'FED':'Editor and Full Editor Name',\n",
    "                      'CN':'Corporate Author', 'MID':'Manuscript Identifier', \n",
    "                      'IR':'Investigator name and Full Investigator Name'\n",
    "                      }, inplace = True)\n",
    "\n",
    "\n",
    "publication_data['keyword'] = keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "73e13c70-f09a-46f5-a8da-41809948be67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of publications that contain the term ((\"Artificial Intelligence\"[Mesh] OR \"Generative Artificial Intelligence\"[Mesh] OR \"artificial intelligence\" OR \"informatics\" OR \"machine learning\" OR \"deep learning\" OR \"neural network*\" OR \"AI\" OR \"large language\" OR \"chatgpt\") AND (\"Dentistry\"[Mesh] OR \"Evidence-Based Dentistry\"[Mesh] OR \"Mouth\"[Mesh] OR \"Oral Medicine\"[Mesh] OR \"dental[ti]\" OR \"oral\"[ti] OR \"dentistry\"[ti] OR \"mouth\"[ti] OR \"teeth\"[ti] OR \"tooth\"[ti] OR \"buccal\"[ti] OR \"pharynx\"[ti] OR \"pharyngeal\"[ti] OR \"tongue\"[ti] OR \"maxillary\"[ti] OR \"mandibular\"[ti])) AND ((\"2020/01/01\"[Date - Publication] : \"3000\"[Date - Publication])): 5585\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 56/56 [00:55<00:00,  1.01it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nxviz\n",
    "import difflib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "from dateutil import parser\n",
    "from iso3166 import countries\n",
    "import pycountry_convert as pc\n",
    "import country_converter as coco\n",
    "from itertools import combinations\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "\n",
    "# Change this email to your email address\n",
    "Entrez.email = \"pratapsingh@1102@gmail.com\"\n",
    "\n",
    "keyword = \"\"\"((\"Artificial Intelligence\"[Mesh] OR \"Generative Artificial Intelligence\"[Mesh] OR \"artificial intelligence\" OR \"informatics\" OR \"machine learning\" OR \"deep learning\" OR \"neural network*\" OR \"AI\" OR \"large language\" OR \"chatgpt\") AND (\"Dentistry\"[Mesh] OR \"Evidence-Based Dentistry\"[Mesh] OR \"Mouth\"[Mesh] OR \"Oral Medicine\"[Mesh] OR \"dental[ti]\" OR \"oral\"[ti] OR \"dentistry\"[ti] OR \"mouth\"[ti] OR \"teeth\"[ti] OR \"tooth\"[ti] OR \"buccal\"[ti] OR \"pharynx\"[ti] OR \"pharyngeal\"[ti] OR \"tongue\"[ti] OR \"maxillary\"[ti] OR \"mandibular\"[ti])) AND ((\"2020/01/01\"[Date - Publication] : \"3000\"[Date - Publication]))\"\"\"\n",
    "\n",
    "result = Entrez.read(Entrez.esearch(db=\"pubmed\", retmax=10, term=keyword))\n",
    "print(\n",
    "    \"Total number of publications that contain the term {}: {}\".format(\n",
    "        keyword, result[\"Count\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fetch all ids\n",
    "MAX_COUNT = result[\"Count\"]\n",
    "result = Entrez.read(\n",
    "    Entrez.esearch(db=\"pubmed\", retmax=result[\"Count\"], term=keyword)\n",
    ")\n",
    "\n",
    "ids = result[\"IdList\"]\n",
    "\n",
    "batch_size = 100\n",
    "batches = [ids[x: x + 100] for x in range(0, len(ids), batch_size)]\n",
    "\n",
    "record_list = []\n",
    "for batch in tqdm(batches):\n",
    "    h = Entrez.efetch(db=\"pubmed\", id=batch, rettype=\"medline\", retmode=\"text\")\n",
    "    records = Medline.parse(h)\n",
    "    record_list.extend(list(records))\n",
    "print(\"Complete.\")\n",
    "\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "publication_data1 = pd.DataFrame(record_list)\n",
    "publication_data1.rename(columns = {'AB':'Abstract', 'CI':'Copyright Information',\n",
    "                     'AD':'Affiliation', 'IRAD':'Investigator Affiliation',\n",
    "                     'AU':'Author', 'FAU':'Full Author',\n",
    "                      'COIS':'Conflict of Interest Statement', 'CRDT':'Create Date',\n",
    "                      'DEP':'Date of Electronic Publication', 'DP':'Date of Publication',\n",
    "                      'EN':'Edition', 'ED':'Editor',\n",
    "                      'GN':'General Note', 'FIR':'Full Investigator Name',\n",
    "                      'JT':'Journal Title', 'RF':'Number of References',\n",
    "                      'PL':'Place of Publication', 'PST':'Publication Status',\n",
    "                      'PT':'Publication Type', 'PUBM':'Publication Model',\n",
    "                      'NM':'Substance Name', 'TI':'Title', 'LID':'Location Identifier',\n",
    "                      'PMID':'PubMed Unique Identifier', 'OWN':'Owner', 'STAT':'Status', 'LR':'Date Last Revised', 'IS':'ISSN', \n",
    "                      'VI':'Volume', 'IP':'Issue', 'PG':'Pagination',\n",
    "                      'LA':'Language', 'TA': 'Journal Title Abbreviation', 'JID': 'NLM Unique ID', \n",
    "                      'PMC':'PubMed Central Identifier', 'OTO':'Other Term Owner','OT':'Other Term', 'EDAT':'Entrez Date', \n",
    "                      'MHDA':'MeSH Date', 'PHST':'Publication History Status', 'AID':'Article Identifier', 'SO':'Source', \n",
    "                      'AUID':'Author Identifier', 'GR':'Grant Number', 'SB':'Subset', 'SI': 'Secondary Source ID',\n",
    "                      'DCOM':'Date Completed', 'RN': 'Registry Number/EC Number', 'MH': 'MeSH Terms', 'BTI':'Book Title', \n",
    "                      'PMCR':'PubMed Central Release', 'FED':'Editor and Full Editor Name',\n",
    "                      'CN':'Corporate Author', 'MID':'Manuscript Identifier', \n",
    "                      'IR':'Investigator name and Full Investigator Name'\n",
    "                      }, inplace = True)\n",
    "\n",
    "\n",
    "publication_data1['keyword'] = keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 259,
   "id": "37d64350-c1ec-4f26-bc08-e4d1d0acf7ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.concat([publication_data, publication_data1], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "2633dd5a-9b4a-4f82-a31f-238481da7237",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(11759, 68)"
      ]
     },
     "execution_count": 260,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "id": "ebc24116-a07f-4ced-8632-c031ba22df2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "who_region_map = {\n",
    "    # African Region (AFRO)\n",
    "    'Algeria': 'AFRO', 'Angola': 'AFRO', 'Benin': 'AFRO', 'Botswana': 'AFRO', 'Burkina Faso': 'AFRO',\n",
    "    'Burundi': 'AFRO', 'Cabo Verde': 'AFRO', 'Cameroon': 'AFRO', 'Central African Republic': 'AFRO',\n",
    "    'Chad': 'AFRO', 'Comoros': 'AFRO', 'Congo': 'AFRO', 'Côte d’Ivoire': 'AFRO', 'Democratic Republic of the Congo': 'AFRO',\n",
    "    'Equatorial Guinea': 'AFRO', 'Eritrea': 'AFRO', 'Eswatini': 'AFRO', 'Ethiopia': 'AFRO', 'Gabon': 'AFRO',\n",
    "    'Gambia': 'AFRO', 'Ghana': 'AFRO', 'Guinea': 'AFRO', 'Guinea-Bissau': 'AFRO', 'Kenya': 'AFRO',\n",
    "    'Lesotho': 'AFRO', 'Liberia': 'AFRO', 'Madagascar': 'AFRO', 'Malawi': 'AFRO', 'Mali': 'AFRO',\n",
    "    'Mauritania': 'AFRO', 'Mauritius': 'AFRO', 'Mozambique': 'AFRO', 'Namibia': 'AFRO', 'Niger': 'AFRO',\n",
    "    'Nigeria': 'AFRO', 'Rwanda': 'AFRO', 'Sao Tome and Principe': 'AFRO', 'Senegal': 'AFRO', 'Seychelles': 'AFRO',\n",
    "    'Sierra Leone': 'AFRO', 'South Africa': 'AFRO', 'South Sudan': 'AFRO', 'Togo': 'AFRO', 'Uganda': 'AFRO',\n",
    "    'United Republic of Tanzania': 'AFRO', 'Zambia': 'AFRO', 'Zimbabwe': 'AFRO',\n",
    "\n",
    "    # Region of the Americas (PAHO)\n",
    "    'Antigua and Barbuda': 'PAHO', 'Argentina': 'PAHO', 'Bahamas': 'PAHO', 'Barbados': 'PAHO', 'Belize': 'PAHO',\n",
    "    'Bolivia': 'PAHO', 'Brazil': 'PAHO', 'Canada': 'PAHO', 'Chile': 'PAHO', 'Colombia': 'PAHO',\n",
    "    'Costa Rica': 'PAHO', 'Cuba': 'PAHO', 'Dominica': 'PAHO', 'Dominican Republic': 'PAHO', 'Ecuador': 'PAHO',\n",
    "    'El Salvador': 'PAHO', 'Grenada': 'PAHO', 'Guatemala': 'PAHO', 'Guyana': 'PAHO', 'Haiti': 'PAHO',\n",
    "    'Honduras': 'PAHO', 'Jamaica': 'PAHO', 'Mexico': 'PAHO', 'Nicaragua': 'PAHO', 'Panama': 'PAHO',\n",
    "    'Paraguay': 'PAHO', 'Peru': 'PAHO', 'Saint Kitts and Nevis': 'PAHO', 'Saint Lucia': 'PAHO',\n",
    "    'Saint Vincent and the Grenadines': 'PAHO', 'Suriname': 'PAHO', 'Trinidad and Tobago': 'PAHO',\n",
    "    'United States': 'PAHO', 'Uruguay': 'PAHO', 'Venezuela': 'PAHO',\n",
    "\n",
    "    # South-East Asia Region (SEARO)\n",
    "    'Bangladesh': 'SEARO', 'Bhutan': 'SEARO', 'DPR Korea': 'SEARO', 'India': 'SEARO',\n",
    "    'Indonesia': 'SEARO', 'Maldives': 'SEARO', 'Myanmar': 'SEARO', 'Nepal': 'SEARO',\n",
    "    'Sri Lanka': 'SEARO', 'Thailand': 'SEARO', 'Timor-Leste': 'SEARO',\n",
    "\n",
    "    # Eastern Mediterranean Region (EMRO)\n",
    "    'Afghanistan': 'EMRO', 'Bahrain': 'EMRO', 'Djibouti': 'EMRO', 'Egypt': 'EMRO', 'Iran': 'EMRO',\n",
    "    'Iraq': 'EMRO', 'Jordan': 'EMRO', 'Kuwait': 'EMRO', 'Lebanon': 'EMRO', 'Libya': 'EMRO',\n",
    "    'Morocco': 'EMRO', 'Oman': 'EMRO', 'Pakistan': 'EMRO', 'Palestine': 'EMRO', 'Qatar': 'EMRO',\n",
    "    'Saudi Arabia': 'EMRO', 'Somalia': 'EMRO', 'Sudan': 'EMRO', 'Syrian Arab Republic': 'EMRO',\n",
    "    'Tunisia': 'EMRO', 'United Arab Emirates': 'EMRO', 'Yemen': 'EMRO',\n",
    "\n",
    "    # European Region (EURO)\n",
    "    'Albania': 'EURO', 'Andorra': 'EURO', 'Armenia': 'EURO', 'Austria': 'EURO', 'Azerbaijan': 'EURO',\n",
    "    'Belarus': 'EURO', 'Belgium': 'EURO', 'Bosnia and Herzegovina': 'EURO', 'Bulgaria': 'EURO', 'Croatia': 'EURO',\n",
    "    'Cyprus': 'EURO', 'Czech Republic': 'EURO', 'Denmark': 'EURO', 'Estonia': 'EURO', 'Finland': 'EURO',\n",
    "    'France': 'EURO', 'Georgia': 'EURO', 'Germany': 'EURO', 'Greece': 'EURO', 'Hungary': 'EURO',\n",
    "    'Iceland': 'EURO', 'Ireland': 'EURO', 'Israel': 'EURO', 'Italy': 'EURO', 'Kazakhstan': 'EURO',\n",
    "    'Kyrgyzstan': 'EURO', 'Latvia': 'EURO', 'Lithuania': 'EURO', 'Luxembourg': 'EURO', 'Malta': 'EURO',\n",
    "    'Monaco': 'EURO', 'Montenegro': 'EURO', 'Netherlands': 'EURO', 'North Macedonia': 'EURO',\n",
    "    'Norway': 'EURO', 'Poland': 'EURO', 'Portugal': 'EURO', 'Republic of Moldova': 'EURO', 'Romania': 'EURO',\n",
    "    'Russian Federation': 'EURO', 'San Marino': 'EURO', 'Serbia': 'EURO', 'Slovakia': 'EURO',\n",
    "    'Slovenia': 'EURO', 'Spain': 'EURO', 'Sweden': 'EURO', 'Switzerland': 'EURO', 'Tajikistan': 'EURO',\n",
    "    'Turkey': 'EURO', 'Turkmenistan': 'EURO', 'Ukraine': 'EURO', 'United Kingdom': 'EURO',\n",
    "    'Uzbekistan': 'EURO', 'England': 'EURO', 'Scotland': 'EURO', 'Italy': 'EURO',\n",
    "\n",
    "    # Western Pacific Region (WPRO)\n",
    "    'Australia': 'WPRO', 'Brunei Darussalam': 'WPRO', 'Cambodia': 'WPRO', 'China': 'WPRO',\n",
    "    'Fiji': 'WPRO', 'Japan': 'WPRO', 'Lao People’s Democratic Republic': 'WPRO', 'Malaysia': 'WPRO',\n",
    "    'Marshall Islands': 'WPRO', 'Micronesia': 'WPRO', 'Mongolia': 'WPRO', 'Nauru': 'WPRO',\n",
    "    'New Zealand': 'WPRO', 'Palau': 'WPRO', 'Papua New Guinea': 'WPRO', 'Philippines': 'WPRO',\n",
    "    'Republic of Korea': 'WPRO', 'Samoa': 'WPRO', 'Singapore': 'WPRO', 'Solomon Islands': 'WPRO',\n",
    "    'Tonga': 'WPRO', 'Tuvalu': 'WPRO', 'Vanuatu': 'WPRO', 'Viet Nam': 'WPRO', 'Korea (South)': 'WPRO'\n",
    "}\n",
    "\n",
    "# Preprocess WHO region map to lowercase for fuzzy matching\n",
    "who_region_map_lower = {k.lower(): v for k, v in who_region_map.items()}\n",
    "\n",
    "def relaxed_who_region_lookup(country_name, mapping, cutoff=0.75):\n",
    "    if pd.isna(country_name):\n",
    "        return 'Unknown'\n",
    "    country_name_lc = country_name.strip().lower()\n",
    "    \n",
    "    # Direct match first\n",
    "    if country_name_lc in mapping:\n",
    "        return mapping[country_name_lc]\n",
    "\n",
    "    # Fuzzy match\n",
    "    match = difflib.get_close_matches(country_name_lc, mapping.keys(), n=1, cutoff=cutoff)\n",
    "    if match:\n",
    "        return mapping[match[0]]\n",
    "    return 'Unknown'\n",
    "\n",
    "merged['WHO Region'] = merged['Place of Publication'].apply(\n",
    "    lambda x: relaxed_who_region_lookup(x, who_region_map_lower)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 262,
   "id": "4c5696ea-44e2-4e62-b8f4-abf953e9ac46",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "e = merged.copy()\n",
    "e['Date Last Revised']= pd.to_datetime(e['Date Last Revised'])\n",
    "e['Entrez Date']= pd.to_datetime(e['Entrez Date'])\n",
    "e['Date Completed']= pd.to_datetime(e['Date Completed'])\n",
    "# e['Date of Publication']= pd.to_datetime(e['Date of Publication'])\n",
    "e['Date of Electronic Publication']= pd.to_datetime(e['Date of Electronic Publication'])\n",
    "def approximate_date(date_str):\n",
    "    if pd.isnull(date_str):\n",
    "        return pd.NaT\n",
    "    s = str(date_str)\n",
    "    # Replace a month range \"Jan-Mar\" with just \"Jan\"\n",
    "    s = re.sub(r'([A-Za-z]{3,9})-[A-Za-z]{3,9}', r'\\1', s)\n",
    "    # If only a year, append Jan\n",
    "    if re.fullmatch(r'\\d{4}', s):\n",
    "        s += \" Jan\"\n",
    "    try:\n",
    "        return parser.parse(s, default=parser.parse(\"1900-01-01\"))\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "e['Date of Publication'] = e['Date of Publication'].apply(approximate_date)\n",
    "e['Publication Year'] = pd.DatetimeIndex(e['Date of Publication']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 263,
   "id": "94357924-3c37-4225-a67c-15851a5ffd74",
   "metadata": {},
   "outputs": [],
   "source": [
    "e.to_excel('AI in Dentistry Data.xlsx')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 265,
   "id": "372030c0-4cd2-4b7e-a358-939d7ee5b426",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "WHO Region\n",
       "EURO       6145\n",
       "PAHO       4748\n",
       "WPRO        650\n",
       "SEARO       133\n",
       "EMRO         53\n",
       "Unknown      19\n",
       "AFRO         11\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 265,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['WHO Region'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "id": "2cce5782-9331-4521-aa03-b49e6338c0f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Place of Publication\n",
       "United States                4654\n",
       "England                      3027\n",
       "Switzerland                   933\n",
       "Germany                       570\n",
       "Netherlands                   569\n",
       "Denmark                       303\n",
       "China                         254\n",
       "Japan                         223\n",
       "Russia (Federation)           138\n",
       "Italy                         122\n",
       "India                         117\n",
       "France                        116\n",
       "Ireland                        97\n",
       "Scotland                       80\n",
       "Australia                      56\n",
       "Canada                         51\n",
       "Greece                         46\n",
       "New Zealand                    42\n",
       "Korea (South)                  41\n",
       "Brazil                         40\n",
       "Singapore                      33\n",
       "Sweden                         32\n",
       "Poland                         29\n",
       "Spain                          17\n",
       "Thailand                       16\n",
       "Romania                        15\n",
       "Georgia (Republic)             15\n",
       "Belgium                        13\n",
       "Egypt                          12\n",
       "United Arab Emirates           12\n",
       "Saudi Arabia                   10\n",
       "Iran                           10\n",
       "Pakistan                        9\n",
       "South Africa                    7\n",
       "Croatia                         6\n",
       "Austria                         5\n",
       "Bulgaria                        5\n",
       "Turkey                          5\n",
       "China (Republic : 1949- )       4\n",
       "Norway                          4\n",
       "Czech Republic                  3\n",
       "Argentina                       3\n",
       "Israel                          3\n",
       "Finland                         2\n",
       "Uganda                          2\n",
       "Serbia                          2\n",
       "Cyprus                          1\n",
       "Lithuania                       1\n",
       "Nigeria                         1\n",
       "Kenya                           1\n",
       "Malaysia                        1\n",
       "Ukraine                         1\n",
       "Name: count, dtype: int64"
      ]
     },
     "execution_count": 264,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['Place of Publication'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4b98c13c-5b40-4bc1-a19e-d6656fd17bd7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1946-01-01 00:00:00\n",
      "2025-10-15 00:00:00\n",
      "61\n",
      "1946.0\n",
      "2025.0\n",
      "61\n"
     ]
    }
   ],
   "source": [
    "print(e['Date of Publication'].min())\n",
    "print(e['Date of Publication'].max())\n",
    "print(e['Date of Publication'].isna().sum())\n",
    "\n",
    "print(e['Publication Year'].min())\n",
    "print(e['Publication Year'].max())\n",
    "print(e['Publication Year'].isna().sum())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "adfb7c24-2078-465d-b219-5d0433a2dc30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cut points (years that split into 6 equal parts):\n",
      "Cut 1: 2005.0\n",
      "Cut 2: 2015.0\n",
      "Cut 3: 2019.0\n",
      "Cut 4: 2022.0\n",
      "Cut 5: 2024.0\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "years = pd.to_numeric(e['Publication Year'], errors='coerce').dropna()\n",
    "cut_points = years.quantile([i/6 for i in range(1, 6)]).values\n",
    "\n",
    "print(\"Cut points (years that split into 6 equal parts):\")\n",
    "for i, cp in enumerate(cut_points, 1):\n",
    "    print(f\"Cut {i}: {cp}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "51d5a9b3-c368-4cbf-85b3-158da6b816d3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     Period   Year Range  Count\n",
      "0  Period 1  1946 – 2005   1991\n",
      "1  Period 2  2006 – 2015   2202\n",
      "2  Period 3  2016 – 2019   1760\n",
      "3  Period 4  2020 – 2022   2567\n",
      "4  Period 5  2023 – 2024   2392\n",
      "5  Period 6  2025 – 2026    774\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Use your existing bins and labels\n",
    "years = pd.to_numeric(e['Publication Year'], errors='coerce').dropna()\n",
    "cut_points = years.quantile([i/6 for i in range(1, 6)]).values\n",
    "bins = [years.min()-1] + list(cut_points) + [years.max()+1]\n",
    "labels = [f\"Period {i+1}\" for i in range(6)]\n",
    "e['Period'] = pd.cut(e['Publication Year'], bins=bins, labels=labels)\n",
    "\n",
    "# Prepare and print a summary table with ranges and counts\n",
    "summary = []\n",
    "for i in range(len(labels)):\n",
    "    left = int(bins[i]+1)  # Make left edge inclusive\n",
    "    right = int(bins[i+1]) # Right edge (could be float, so cast to int)\n",
    "    count = (e['Period'] == labels[i]).sum()\n",
    "    summary.append({'Period': labels[i], 'Year Range': f\"{left} – {right}\", 'Count': count})\n",
    "\n",
    "summary_df = pd.DataFrame(summary)\n",
    "print(summary_df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "id": "5e44a965-730b-4f63-acac-4594901c3010",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1737, 70)"
      ]
     },
     "execution_count": 109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = '1946-01-01', '2003-12-31'\n",
    "mask = e['Date of Publication'].between(start, end)\n",
    "e[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "id": "bf446399-3480-4773-9f47-57eddd20ec34",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1764, 70)"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = '2004-01-01', '2013-12-31'\n",
    "mask = e['Date of Publication'].between(start, end)\n",
    "e[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "id": "1c1d6582-99db-4f12-9b51-e3bb52fba182",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1934, 70)"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = '2014-01-01', '2018-12-31'\n",
    "mask = e['Date of Publication'].between(start, end)\n",
    "e[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "517fd0f3-3390-4aeb-9575-e006a4574fcf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2136, 70)"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = '2019-01-01', '2021-12-31'\n",
    "mask = e['Date of Publication'].between(start, end)\n",
    "e[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "id": "8d427b3b-8b12-47bb-8d5e-a865e72ff6f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1928, 70)"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = '2022-01-01', '2023-12-31'\n",
    "mask = e['Date of Publication'].between(start, end)\n",
    "e[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "b96d83c1-3e55-4260-83db-793f3584a8b9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2187, 70)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "start, end = '2024-01-01', '2026-12-31'\n",
    "mask = e['Date of Publication'].between(start, end)\n",
    "e[mask].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bc1e2c9-0a02-4bf7-9402-90167ff67b1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "ENTITY_KEYWORDS = [\n",
    "    r'University', r'Institut(?:e|o)', r'Hospital',\n",
    "    r'Corporation', r'Company', r'Ltd', r'LLC',\n",
    "    r'Academy', r'Medical Center', r'Research Group'\n",
    "]\n",
    "ENTITY_PATTERN = re.compile(r'(' + '|'.join(ENTITY_KEYWORDS) + r')', re.IGNORECASE)\n",
    "\n",
    "def extract_entity_keep_tail(affil_str):\n",
    "    if not isinstance(affil_str, str):\n",
    "        return affil_str\n",
    "    parts = [p.strip() for p in affil_str.split(',')]\n",
    "    for i, part in enumerate(parts):\n",
    "        if ENTITY_PATTERN.search(part):\n",
    "            # Return from this part to the end, joined by commas\n",
    "            return ', '.join(parts[i:])\n",
    "    # If nothing found, return the original string\n",
    "    return affil_str\n",
    "\n",
    "def entity_list_keep_tail(affil_list):\n",
    "    if isinstance(affil_list, list):\n",
    "        return [extract_entity_keep_tail(a) for a in affil_list]\n",
    "    else:\n",
    "        return extract_entity_keep_tail(affil_list)\n",
    "\n",
    "e['Entity'] = e['Affiliation'].apply(entity_list_keep_tail)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 172,
   "id": "d8bac51a-3ce2-4a62-97dc-a425274c39bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Center for Regenerative and Developmental Biology, The Forsyth Institute, Cambridge, MA, United States.',\n",
       " 'Department of Prosthodontics, Universitas Gadjah Mada, Yogyakarta, Indonesia.',\n",
       " 'Center for Regenerative and Developmental Biology, The Forsyth Institute, Cambridge, MA, United States.',\n",
       " 'Division of Neonatology, Cooper University Hospital, Camden, NJ, United States.',\n",
       " 'Center for Regenerative and Developmental Biology, The Forsyth Institute, Cambridge, MA, United States.',\n",
       " 'Center for Engineering in Medicine, Department of Surgery, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States.',\n",
       " 'Shriners Hospital for Children, Boston, MA, United States.',\n",
       " 'Department of Molecular Biology, Institute of Biomedical Sciences, Tokushima University, Tokushima, Japan.',\n",
       " 'Faculty of Human Life Studies, Hiroshima Jogakuin University, Hiroshima, Japan.',\n",
       " 'Center for Craniofacial Molecular Biology, Herman Ostrow School of Dentistry of USC, University of Southern California, Los Angeles, CA, United States.',\n",
       " 'University of Utah, Salt Lake City, UT, United States.',\n",
       " 'Center for Engineering in Medicine, Department of Surgery, Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States.',\n",
       " 'Shriners Hospital for Children, Boston, MA, United States.']"
      ]
     },
     "execution_count": 172,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['Affiliation'][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 173,
   "id": "51014c9d-9265-48f0-b10a-706a4b6793ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['The Forsyth Institute, Cambridge, MA, United States.',\n",
       " 'Department of Prosthodontics, Universitas Gadjah Mada, Yogyakarta, Indonesia.',\n",
       " 'The Forsyth Institute, Cambridge, MA, United States.',\n",
       " 'Cooper University Hospital, Camden, NJ, United States.',\n",
       " 'The Forsyth Institute, Cambridge, MA, United States.',\n",
       " 'Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States.',\n",
       " 'Shriners Hospital for Children, Boston, MA, United States.',\n",
       " 'Institute of Biomedical Sciences, Tokushima University, Tokushima, Japan.',\n",
       " 'Hiroshima Jogakuin University, Hiroshima, Japan.',\n",
       " 'University of Southern California, Los Angeles, CA, United States.',\n",
       " 'University of Utah, Salt Lake City, UT, United States.',\n",
       " 'Massachusetts General Hospital and Harvard Medical School, Boston, MA, United States.',\n",
       " 'Shriners Hospital for Children, Boston, MA, United States.']"
      ]
     },
     "execution_count": 173,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e['Entity'][18]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "3a940314-edf4-47ad-9f3f-ca27175b352d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Total Papers</th>\n",
       "      <th>Missing Affiliations</th>\n",
       "      <th>Single Affiliation</th>\n",
       "      <th>2 Affiliations</th>\n",
       "      <th>3+ Affiliations</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946-01-01 to 2003-12-31</td>\n",
       "      <td>1737</td>\n",
       "      <td>428</td>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-01 to 2013-12-31</td>\n",
       "      <td>1764</td>\n",
       "      <td>68</td>\n",
       "      <td>1659</td>\n",
       "      <td>2</td>\n",
       "      <td>35</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01 to 2018-12-31</td>\n",
       "      <td>1934</td>\n",
       "      <td>77</td>\n",
       "      <td>222</td>\n",
       "      <td>76</td>\n",
       "      <td>1559</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 to 2021-12-31</td>\n",
       "      <td>2136</td>\n",
       "      <td>73</td>\n",
       "      <td>38</td>\n",
       "      <td>65</td>\n",
       "      <td>1960</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 to 2023-12-31</td>\n",
       "      <td>1928</td>\n",
       "      <td>57</td>\n",
       "      <td>49</td>\n",
       "      <td>73</td>\n",
       "      <td>1749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-01 to 2026-12-31</td>\n",
       "      <td>2187</td>\n",
       "      <td>74</td>\n",
       "      <td>63</td>\n",
       "      <td>101</td>\n",
       "      <td>1949</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Period  Total Papers  Missing Affiliations  \\\n",
       "0  1946-01-01 to 2003-12-31          1737                   428   \n",
       "1  2004-01-01 to 2013-12-31          1764                    68   \n",
       "2  2014-01-01 to 2018-12-31          1934                    77   \n",
       "3  2019-01-01 to 2021-12-31          2136                    73   \n",
       "4  2022-01-01 to 2023-12-31          1928                    57   \n",
       "5  2024-01-01 to 2026-12-31          2187                    74   \n",
       "\n",
       "   Single Affiliation  2 Affiliations  3+ Affiliations  \n",
       "0                1309               0                0  \n",
       "1                1659               2               35  \n",
       "2                 222              76             1559  \n",
       "3                  38              65             1960  \n",
       "4                  49              73             1749  \n",
       "5                  63             101             1949  "
      ]
     },
     "execution_count": 127,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "periods = [\n",
    "    ('1946-01-01', '2003-12-31'),\n",
    "    ('2004-01-01', '2013-12-31'),\n",
    "    ('2014-01-01', '2018-12-31'),\n",
    "    ('2019-01-01', '2021-12-31'),\n",
    "    ('2022-01-01', '2023-12-31'),\n",
    "    ('2024-01-01', '2026-12-31'),\n",
    "]\n",
    "\n",
    "def affil_count(affil):\n",
    "    if affil is None:\n",
    "        return 'missing'\n",
    "    if isinstance(affil, float) and np.isnan(affil):\n",
    "        return 'missing'\n",
    "    if isinstance(affil, (list, np.ndarray)):\n",
    "        l = len(affil)\n",
    "        if l == 0:\n",
    "            return 'missing'\n",
    "        elif l == 1:\n",
    "            return 'single'\n",
    "        elif l == 2:\n",
    "            return 'two'\n",
    "        elif l >= 3:\n",
    "            return 'three_plus'\n",
    "        else:\n",
    "            return 'other'\n",
    "    if isinstance(affil, str):\n",
    "        if affil.strip() == '':\n",
    "            return 'missing'\n",
    "        else:\n",
    "            return 'single'\n",
    "    return 'other'\n",
    "\n",
    "results = []\n",
    "for start, end in periods:\n",
    "    mask = (e['Date of Publication'] >= start) & (e['Date of Publication'] <= end)\n",
    "    subset = e.loc[mask]\n",
    "    total = len(subset)\n",
    "\n",
    "    affil_cats = subset['Affiliation'].apply(affil_count)\n",
    "    missing_affil = (affil_cats == 'missing').sum()\n",
    "    single = (affil_cats == 'single').sum()\n",
    "    two = (affil_cats == 'two').sum()\n",
    "    three_plus = (affil_cats == 'three_plus').sum()\n",
    "\n",
    "    results.append({\n",
    "        'Period': f\"{start} to {end}\",\n",
    "        'Total Papers': total,\n",
    "        'Missing Affiliations': missing_affil,\n",
    "        'Single Affiliation': single,\n",
    "        '2 Affiliations': two,\n",
    "        '3+ Affiliations': three_plus\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "id": "0b5f652f-52d9-41c0-9a8a-db15ce509a7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Period</th>\n",
       "      <th>Total Papers</th>\n",
       "      <th>Missing Affiliations</th>\n",
       "      <th>Single Affiliation</th>\n",
       "      <th>2 Affiliations</th>\n",
       "      <th>3+ Affiliations</th>\n",
       "      <th>Missing Entities</th>\n",
       "      <th>Single Entity</th>\n",
       "      <th>2 Entities</th>\n",
       "      <th>3+ Entities</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946-01-01 to 2003-12-31</td>\n",
       "      <td>1737</td>\n",
       "      <td>428</td>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>428</td>\n",
       "      <td>1309</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-01-01 to 2013-12-31</td>\n",
       "      <td>1764</td>\n",
       "      <td>68</td>\n",
       "      <td>1663</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "      <td>68</td>\n",
       "      <td>1663</td>\n",
       "      <td>5</td>\n",
       "      <td>28</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-01-01 to 2018-12-31</td>\n",
       "      <td>1934</td>\n",
       "      <td>77</td>\n",
       "      <td>316</td>\n",
       "      <td>245</td>\n",
       "      <td>1296</td>\n",
       "      <td>77</td>\n",
       "      <td>365</td>\n",
       "      <td>308</td>\n",
       "      <td>1184</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-01-01 to 2021-12-31</td>\n",
       "      <td>2136</td>\n",
       "      <td>73</td>\n",
       "      <td>145</td>\n",
       "      <td>301</td>\n",
       "      <td>1617</td>\n",
       "      <td>73</td>\n",
       "      <td>213</td>\n",
       "      <td>398</td>\n",
       "      <td>1452</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-01-01 to 2023-12-31</td>\n",
       "      <td>1928</td>\n",
       "      <td>57</td>\n",
       "      <td>134</td>\n",
       "      <td>252</td>\n",
       "      <td>1485</td>\n",
       "      <td>57</td>\n",
       "      <td>184</td>\n",
       "      <td>346</td>\n",
       "      <td>1341</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>2024-01-01 to 2026-12-31</td>\n",
       "      <td>2187</td>\n",
       "      <td>74</td>\n",
       "      <td>151</td>\n",
       "      <td>304</td>\n",
       "      <td>1658</td>\n",
       "      <td>74</td>\n",
       "      <td>217</td>\n",
       "      <td>381</td>\n",
       "      <td>1515</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Period  Total Papers  Missing Affiliations  \\\n",
       "0  1946-01-01 to 2003-12-31          1737                   428   \n",
       "1  2004-01-01 to 2013-12-31          1764                    68   \n",
       "2  2014-01-01 to 2018-12-31          1934                    77   \n",
       "3  2019-01-01 to 2021-12-31          2136                    73   \n",
       "4  2022-01-01 to 2023-12-31          1928                    57   \n",
       "5  2024-01-01 to 2026-12-31          2187                    74   \n",
       "\n",
       "   Single Affiliation  2 Affiliations  3+ Affiliations  Missing Entities  \\\n",
       "0                1309               0                0               428   \n",
       "1                1663               5               28                68   \n",
       "2                 316             245             1296                77   \n",
       "3                 145             301             1617                73   \n",
       "4                 134             252             1485                57   \n",
       "5                 151             304             1658                74   \n",
       "\n",
       "   Single Entity  2 Entities  3+ Entities  \n",
       "0           1309           0            0  \n",
       "1           1663           5           28  \n",
       "2            365         308         1184  \n",
       "3            213         398         1452  \n",
       "4            184         346         1341  \n",
       "5            217         381         1515  "
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "periods = [\n",
    "    ('1946-01-01', '2003-12-31'),\n",
    "    ('2004-01-01', '2013-12-31'),\n",
    "    ('2014-01-01', '2018-12-31'),\n",
    "    ('2019-01-01', '2021-12-31'),\n",
    "    ('2022-01-01', '2023-12-31'),\n",
    "    ('2024-01-01', '2026-12-31'),\n",
    "]\n",
    "\n",
    "def affil_count(val):\n",
    "    if val is None:\n",
    "        return 'missing'\n",
    "    if isinstance(val, float) and np.isnan(val):\n",
    "        return 'missing'\n",
    "    if isinstance(val, (list, np.ndarray)):\n",
    "        l = len(val)\n",
    "        if l == 0:\n",
    "            return 'missing'\n",
    "        elif l == 1:\n",
    "            return 'single'\n",
    "        elif l == 2:\n",
    "            return 'two'\n",
    "        elif l >= 3:\n",
    "            return 'three_plus'\n",
    "        else:\n",
    "            return 'other'\n",
    "    if isinstance(val, str):\n",
    "        if val.strip() == '':\n",
    "            return 'missing'\n",
    "        else:\n",
    "            return 'single'\n",
    "    return 'other'\n",
    "\n",
    "def deduplicate(val):\n",
    "    if isinstance(val, list):\n",
    "        cleaned = [x.strip() for x in val if isinstance(x, str) and x.strip() != '']\n",
    "        return list(set(cleaned))\n",
    "    else:\n",
    "        return val\n",
    "\n",
    "results = []\n",
    "for start, end in periods:\n",
    "    mask = (e['Date of Publication'] >= start) & (e['Date of Publication'] <= end)\n",
    "    subset = e.loc[mask]\n",
    "    total = len(subset)\n",
    "\n",
    "    # Affiliations (deduplicated)\n",
    "    dedup_affils = subset['Affiliation'].apply(deduplicate)\n",
    "    affil_cats = dedup_affils.apply(affil_count)\n",
    "    missing_affil = (affil_cats == 'missing').sum()\n",
    "    single = (affil_cats == 'single').sum()\n",
    "    two = (affil_cats == 'two').sum()\n",
    "    three_plus = (affil_cats == 'three_plus').sum()\n",
    "\n",
    "    # Entities (deduplicated)\n",
    "    dedup_entities = subset['Entity'].apply(deduplicate)\n",
    "    entity_cats = dedup_entities.apply(affil_count)\n",
    "    missing_entity = (entity_cats == 'missing').sum()\n",
    "    single_entity = (entity_cats == 'single').sum()\n",
    "    two_entity = (entity_cats == 'two').sum()\n",
    "    three_plus_entity = (entity_cats == 'three_plus').sum()\n",
    "\n",
    "    results.append({\n",
    "        'Period': f\"{start} to {end}\",\n",
    "        'Total Papers': total,\n",
    "        'Missing Affiliations': missing_affil,\n",
    "        'Single Affiliation': single,\n",
    "        '2 Affiliations': two,\n",
    "        '3+ Affiliations': three_plus,\n",
    "        'Missing Entities': missing_entity,\n",
    "        'Single Entity': single_entity,\n",
    "        '2 Entities': two_entity,\n",
    "        '3+ Entities': three_plus_entity\n",
    "    })\n",
    "\n",
    "summary_df = pd.DataFrame(results)\n",
    "summary_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "id": "51f834d8-35fb-4e82-8ab0-96855081a777",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# for i, row in subset.iterrows():\n",
    "#     affil = deduplicate(row['Affiliation'])\n",
    "#     entity = deduplicate(row['Entity'])\n",
    "#     affil_cat = affil_count(affil)\n",
    "#     entity_cat = affil_count(entity)\n",
    "#     if affil_cat != entity_cat:\n",
    "#         print(\"Affiliation:\", affil, \"(\", affil_cat, \")\")\n",
    "#         print(\"Entity:\", entity, \"(\", entity_cat, \")\")\n",
    "#         print(\"---\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "406528fa-eca5-4f14-8ba1-a73e85d8ffa4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "id": "a79279c7-de49-4bdf-a939-6a4716a03ebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Saved: Institutions_Network_2024_2026.html\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from pyvis.network import Network\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "START, END = 2024, 2026\n",
    "\n",
    "import re\n",
    "\n",
    "# Pre-compile your category patterns for speed & maintainability\n",
    "patterns = {\n",
    "    'Dental': re.compile(\n",
    "        r'\\b('\n",
    "        r'dental|oral|maxillofacial|odontology|stomatology|prosthodontic|'\n",
    "        r'endodontic|orthodontic|periodontic|oral surgery|restorative|periodontology'\n",
    "        r'implantology'\n",
    "        r')\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'Medical': re.compile(\n",
    "        r'\\b('\n",
    "        r'medical|medicine|hospital|clinic|health|cardiology|neurology|oncology|brain|metabolism|cognitive|life science'\n",
    "        r'pediatrics|psychiatry|geriatrics|urology|nephrology|endocrinology|chemistry|infectious|clinical'\n",
    "        r'rheumatology|dermatology|gastroenterology|pulmonology|neuroscience|pharmacotherapy|cellular'\n",
    "        r'otorhinolaryngology|ophthalmology|radiology|anesthesiology|anatomy|biology|molecular|biochemistry|biophysics'\n",
    "        r'pathology|immunology|public health|epidemiology|pharmacology|physiology|cancer|clinical research'\n",
    "        r')\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "    'Technical': re.compile(\n",
    "        r'\\b('\n",
    "        r'technical|technology|engineering|polytechnic|'\n",
    "        r'computer science|informatics|electronics|mechanical|civil|bioengineering'\n",
    "        r'chemical|aerospace|software|electrical|materials science|'\n",
    "        r'robotics|translational|biomedical|bioinformatics'\n",
    "        r')\\b',\n",
    "        re.IGNORECASE\n",
    "    ),\n",
    "}\n",
    "\n",
    "def classify_institute(name: str) -> str:\n",
    "    \"\"\"\n",
    "    Classify an institution name into Dental, Medical, Technical or Other\n",
    "    based on keyword matching.\n",
    "    \"\"\"\n",
    "    for category, pattern in patterns.items():\n",
    "        if pattern.search(name):\n",
    "            return category\n",
    "    return 'Other'\n",
    "\n",
    "\n",
    "type_color = {\n",
    "    'Dental':    '#e31a1c',\n",
    "    'Medical':   '#1f78b4',\n",
    "    'Technical': '#33a02c',\n",
    "    'Other':     'lightgray'\n",
    "}\n",
    "\n",
    "# --- FILTER TO MOST RECENT DECADE ---\n",
    "mask = (\n",
    "    e['Publication Year'].between(START, END) &\n",
    "    e['Affiliation'].apply(lambda lst: isinstance(lst, list) and len(lst) > 1)\n",
    "    # e['WHO Region'] == 'PAHO'\n",
    ")\n",
    "decade_papers = e.loc[mask, 'Affiliation']\n",
    "\n",
    "# --- BUILD EDGES ---\n",
    "edges = []\n",
    "for inst_list in decade_papers:\n",
    "    insts = list(dict.fromkeys(inst_list))\n",
    "    edges += combinations(insts, 2)\n",
    "\n",
    "edge_counts = Counter(edges)\n",
    "edge_df = pd.DataFrame(\n",
    "    [(a, b, w) for (a, b), w in edge_counts.items()],\n",
    "    columns=['Source', 'Target', 'Weight']\n",
    ")\n",
    "\n",
    "# --- CLASSIFY & COLOR ---\n",
    "all_insts = set(edge_df['Source']) | set(edge_df['Target'])\n",
    "inst_type = {i: classify_institute(i) for i in all_insts}\n",
    "\n",
    "# --- RENDER WITH PyVis ---\n",
    "net = Network(\n",
    "    height='100vh', width='100vw',\n",
    "    bgcolor='#222222', font_color='white',\n",
    "    directed=False\n",
    ")\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"nodes\": {\"font\": {\"size\":20, \"color\":\"white\"}},\n",
    "  \"edges\": {\"color\":{\"color\":\"gray\"}, \"width\":2, \"smooth\":false},\n",
    "  \"interaction\": {\"hover\":true, \"tooltipDelay\":50},\n",
    "  \"physics\": {\"barnesHut\": {\"gravitationalConstant\": -20000, \"springLength\":250}}\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "for inst, typ in inst_type.items():\n",
    "    net.add_node(\n",
    "        inst,\n",
    "        label=inst,\n",
    "        title=f\"<b>Institution:</b> {inst}<br><b>Type:</b> {typ}\",\n",
    "        color=type_color[typ]\n",
    "    )\n",
    "\n",
    "for _, row in edge_df.iterrows():\n",
    "    net.add_edge(\n",
    "        row['Source'], row['Target'],\n",
    "        value=row['Weight'],\n",
    "        title=f\"Co‐publications: {row['Weight']}\"\n",
    "    )\n",
    "\n",
    "net.write_html(f\"Institutions_Network_{START}_{END}.html\")\n",
    "print(f\"▶ Saved: Institutions_Network_{START}_{END}.html\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "id": "c3877ee1-c3bb-4dff-b8db-e5b448ee2fe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 194,
   "id": "42e49f8d-920a-45d2-81a5-44e86316334a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Global Metrics ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>edges</th>\n",
       "      <th>density</th>\n",
       "      <th>avg_clustering</th>\n",
       "      <th>largest_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946-2003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-2013</th>\n",
       "      <td>164.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.033518</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-2018</th>\n",
       "      <td>7494.0</td>\n",
       "      <td>26516.0</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.233386</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-2021</th>\n",
       "      <td>8658.0</td>\n",
       "      <td>29540.0</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.126850</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-2023</th>\n",
       "      <td>9273.0</td>\n",
       "      <td>82850.0</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.158193</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-2026</th>\n",
       "      <td>9690.0</td>\n",
       "      <td>32060.0</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.188198</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nodes    edges   density  avg_clustering  largest_cc\n",
       "1946-2003     0.0      0.0  0.000000        0.000000         0.0\n",
       "2004-2013   164.0    448.0  0.033518        0.939024        11.0\n",
       "2014-2018  7494.0  26516.0  0.000944        0.233386       142.0\n",
       "2019-2021  8658.0  29540.0  0.000788        0.126850        82.0\n",
       "2022-2023  9273.0  82850.0  0.001927        0.158193       389.0\n",
       "2024-2026  9690.0  32060.0  0.000683        0.188198       253.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overlap & Jaccard ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>node_jaccard</th>\n",
       "      <th>edge_jaccard</th>\n",
       "      <th>new_nodes</th>\n",
       "      <th>dropped_nodes</th>\n",
       "      <th>new_edges</th>\n",
       "      <th>dropped_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946-2003</td>\n",
       "      <td>2004-2013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-2013</td>\n",
       "      <td>2014-2018</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>7480</td>\n",
       "      <td>150</td>\n",
       "      <td>26508</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-2018</td>\n",
       "      <td>2019-2021</td>\n",
       "      <td>0.016105</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>8402</td>\n",
       "      <td>7238</td>\n",
       "      <td>29337</td>\n",
       "      <td>26313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-2021</td>\n",
       "      <td>2022-2023</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>8858</td>\n",
       "      <td>8243</td>\n",
       "      <td>82375</td>\n",
       "      <td>29065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>2024-2026</td>\n",
       "      <td>0.021383</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>9293</td>\n",
       "      <td>8876</td>\n",
       "      <td>31474</td>\n",
       "      <td>82264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        from         to  node_jaccard  edge_jaccard  new_nodes  dropped_nodes  \\\n",
       "0  1946-2003  2004-2013      0.000000      0.000000        164              0   \n",
       "1  2004-2013  2014-2018      0.001832      0.000297       7480            150   \n",
       "2  2014-2018  2019-2021      0.016105      0.003635       8402           7238   \n",
       "3  2019-2021  2022-2023      0.023693      0.004244       8858           8243   \n",
       "4  2022-2023  2024-2026      0.021383      0.005126       9293           8876   \n",
       "\n",
       "   new_edges  dropped_edges  \n",
       "0        448              0  \n",
       "1      26508            440  \n",
       "2      29337          26313  \n",
       "3      82375          29065  \n",
       "4      31474          82264  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Pickled difference graph → diff_19462003_vs_20042013.gpickle\n",
      "▶ Pickled difference graph → diff_20042013_vs_20142018.gpickle\n",
      "▶ Pickled difference graph → diff_20142018_vs_20192021.gpickle\n",
      "▶ Pickled difference graph → diff_20192021_vs_20222023.gpickle\n",
      "▶ Pickled difference graph → diff_20222023_vs_20242026.gpickle\n",
      "=== Cluster & Color-Mix Comparison ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_nodes</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>avg_edge_weight</th>\n",
       "      <th>num_clusters</th>\n",
       "      <th>same_color_clusters</th>\n",
       "      <th>two_color_clusters</th>\n",
       "      <th>three_color_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946-2003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Technical': 0, 'Dental': 0, 'Medical': 0}</td>\n",
       "      <td>{('Dental', 'Medical'): 0, ('Dental', 'Technic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-2013</th>\n",
       "      <td>164</td>\n",
       "      <td>448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>{'Technical': 1, 'Dental': 1, 'Medical': 17}</td>\n",
       "      <td>{('Dental', 'Medical'): 3, ('Dental', 'Technic...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-2018</th>\n",
       "      <td>7494</td>\n",
       "      <td>26516</td>\n",
       "      <td>1.016782</td>\n",
       "      <td>1338</td>\n",
       "      <td>{'Technical': 49, 'Dental': 94, 'Medical': 614}</td>\n",
       "      <td>{('Dental', 'Medical'): 302, ('Dental', 'Techn...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-2021</th>\n",
       "      <td>8658</td>\n",
       "      <td>29540</td>\n",
       "      <td>1.087204</td>\n",
       "      <td>1509</td>\n",
       "      <td>{'Technical': 80, 'Dental': 135, 'Medical': 596}</td>\n",
       "      <td>{('Dental', 'Medical'): 311, ('Dental', 'Techn...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-2023</th>\n",
       "      <td>9273</td>\n",
       "      <td>82850</td>\n",
       "      <td>1.007677</td>\n",
       "      <td>1467</td>\n",
       "      <td>{'Technical': 75, 'Dental': 181, 'Medical': 438}</td>\n",
       "      <td>{('Dental', 'Medical'): 304, ('Dental', 'Techn...</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-2026</th>\n",
       "      <td>9690</td>\n",
       "      <td>32060</td>\n",
       "      <td>1.028291</td>\n",
       "      <td>1671</td>\n",
       "      <td>{'Technical': 83, 'Dental': 281, 'Medical': 429}</td>\n",
       "      <td>{('Dental', 'Medical'): 367, ('Dental', 'Techn...</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_nodes num_edges avg_edge_weight num_clusters  \\\n",
       "1946-2003         0         0               0            0   \n",
       "2004-2013       164       448             1.0           33   \n",
       "2014-2018      7494     26516        1.016782         1338   \n",
       "2019-2021      8658     29540        1.087204         1509   \n",
       "2022-2023      9273     82850        1.007677         1467   \n",
       "2024-2026      9690     32060        1.028291         1671   \n",
       "\n",
       "                                        same_color_clusters  \\\n",
       "1946-2003       {'Technical': 0, 'Dental': 0, 'Medical': 0}   \n",
       "2004-2013      {'Technical': 1, 'Dental': 1, 'Medical': 17}   \n",
       "2014-2018   {'Technical': 49, 'Dental': 94, 'Medical': 614}   \n",
       "2019-2021  {'Technical': 80, 'Dental': 135, 'Medical': 596}   \n",
       "2022-2023  {'Technical': 75, 'Dental': 181, 'Medical': 438}   \n",
       "2024-2026  {'Technical': 83, 'Dental': 281, 'Medical': 429}   \n",
       "\n",
       "                                          two_color_clusters  \\\n",
       "1946-2003  {('Dental', 'Medical'): 0, ('Dental', 'Technic...   \n",
       "2004-2013  {('Dental', 'Medical'): 3, ('Dental', 'Technic...   \n",
       "2014-2018  {('Dental', 'Medical'): 302, ('Dental', 'Techn...   \n",
       "2019-2021  {('Dental', 'Medical'): 311, ('Dental', 'Techn...   \n",
       "2022-2023  {('Dental', 'Medical'): 304, ('Dental', 'Techn...   \n",
       "2024-2026  {('Dental', 'Medical'): 367, ('Dental', 'Techn...   \n",
       "\n",
       "          three_color_clusters  \n",
       "1946-2003                    0  \n",
       "2004-2013                    3  \n",
       "2014-2018                   59  \n",
       "2019-2021                  100  \n",
       "2022-2023                  132  \n",
       "2024-2026                  139  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Degree Centrality Trajectories ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University of California, San Francisco, CA, USA.</th>\n",
       "      <th>Asociacion Civil Impacta Salud y Educacion, Lima</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946-2003</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-2013</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-2018</th>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-2021</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-2023</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-2026</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           University of California, San Francisco, CA, USA.  \\\n",
       "1946-2003                                           0.000000   \n",
       "2004-2013                                           0.000000   \n",
       "2014-2018                                           0.004137   \n",
       "2019-2021                                           0.000000   \n",
       "2022-2023                                           0.000000   \n",
       "2024-2026                                           0.000000   \n",
       "\n",
       "           Asociacion Civil Impacta Salud y Educacion, Lima  \n",
       "1946-2003                                               0.0  \n",
       "2004-2013                                               0.0  \n",
       "2014-2018                                               0.0  \n",
       "2019-2021                                               0.0  \n",
       "2022-2023                                               0.0  \n",
       "2024-2026                                               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Betweenness Centrality Trajectories ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University of California, San Francisco, CA, USA.</th>\n",
       "      <th>Asociacion Civil Impacta Salud y Educacion, Lima</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946-2003</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-2013</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-2018</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-2021</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-2023</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-2026</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           University of California, San Francisco, CA, USA.  \\\n",
       "1946-2003                                           0.000000   \n",
       "2004-2013                                           0.000000   \n",
       "2014-2018                                           0.000014   \n",
       "2019-2021                                           0.000000   \n",
       "2022-2023                                           0.000000   \n",
       "2024-2026                                           0.000000   \n",
       "\n",
       "           Asociacion Civil Impacta Salud y Educacion, Lima  \n",
       "1946-2003                                               0.0  \n",
       "2004-2013                                               0.0  \n",
       "2014-2018                                               0.0  \n",
       "2019-2021                                               0.0  \n",
       "2022-2023                                               0.0  \n",
       "2024-2026                                               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# ── 1) HTML → NetworkX Loader (find any two DataSets) ─────────────────────────\n",
    "\n",
    "def load_pyvis_html(path):\n",
    "    \"\"\"\n",
    "    Parse a PyVis HTML file by pulling out the first two\n",
    "    new vis.DataSet([...]) blocks (nodes, then edges).\n",
    "    \"\"\"\n",
    "    with open(path, 'r', encoding='utf-8') as f:\n",
    "        html = f.read()\n",
    "\n",
    "    arrays = re.findall(r'new vis\\.DataSet\\(\\s*(\\[[\\s\\S]*?\\])\\s*\\)', \n",
    "                        html, flags=re.S)\n",
    "    if len(arrays) < 2:\n",
    "        raise ValueError(f\"Expected ≥2 DataSet arrays in {path}, found {len(arrays)}\")\n",
    "\n",
    "    nodes = json.loads(arrays[0])\n",
    "    edges = json.loads(arrays[1])\n",
    "\n",
    "    G = nx.Graph()\n",
    "    for n in nodes:\n",
    "        nid = n.pop('id')\n",
    "        G.add_node(nid, **n)\n",
    "    for e in edges:\n",
    "        u, v = e.pop('from'), e.pop('to')\n",
    "        # PyVis calls edge weight \"value\"\n",
    "        if 'value' in e:\n",
    "            e['weight'] = e.pop('value')\n",
    "        G.add_edge(u, v, **e)\n",
    "\n",
    "    return G\n",
    "\n",
    "# ── 2) Analysis Utilities ─────────────────────────────────────────────────────\n",
    "\n",
    "KEY_TYPES = {'Dental', 'Medical', 'Technical'}\n",
    "\n",
    "def graph_metrics(G):\n",
    "    nodes = G.number_of_nodes()\n",
    "    edges = G.number_of_edges()\n",
    "    if nodes == 0 or edges == 0:\n",
    "        avg_clustering = 0.0\n",
    "        largest_cc = 0\n",
    "        density = 0.0\n",
    "    else:\n",
    "        avg_clustering = nx.average_clustering(G, weight='weight')\n",
    "        largest_cc = len(max(nx.connected_components(G), key=len))\n",
    "        density = nx.density(G)\n",
    "    return {\n",
    "        'nodes': nodes,\n",
    "        'edges': edges,\n",
    "        'density': density,\n",
    "        'avg_clustering': avg_clustering,\n",
    "        'largest_cc': largest_cc,\n",
    "    }\n",
    "\n",
    "\n",
    "def top_centralities(G, n=10):\n",
    "    deg_c = nx.degree_centrality(G)\n",
    "    bet_c = nx.betweenness_centrality(G, weight='weight', normalized=True)\n",
    "    top_deg = sorted(deg_c.items(), key=lambda x:-x[1])[:n]\n",
    "    top_bet = sorted(bet_c.items(), key=lambda x:-x[1])[:n]\n",
    "    return pd.DataFrame({\n",
    "        'rank':      list(range(1,n+1)),\n",
    "        'deg_node':  [u for u,_ in top_deg],\n",
    "        'deg_score': [s for _,s in top_deg],\n",
    "        'bet_node':  [u for u,_ in top_bet],\n",
    "        'bet_score': [s for _,s in top_bet],\n",
    "    })\n",
    "\n",
    "def jaccard(a,b):\n",
    "    return len(a & b) / len(a | b) if (a or b) else 0.0\n",
    "\n",
    "def build_diff_graph(G1,G2):\n",
    "    E1, E2 = set(G1.edges()), set(G2.edges())\n",
    "    Gd = nx.Graph()\n",
    "    for n in set(G1)|set(G2):\n",
    "        attrs = G2.nodes[n] if n in G2 else G1.nodes[n]\n",
    "        Gd.add_node(n, **attrs)\n",
    "    for u,v in E1|E2:\n",
    "        color = ('gray' if (u,v) in E1 & E2\n",
    "                 else 'red' if (u,v) in E1\n",
    "                 else 'green')\n",
    "        w = (G1[u][v].get('weight',1) if G1.has_edge(u,v) else 0) + \\\n",
    "            (G2[u][v].get('weight',1) if G2.has_edge(u,v) else 0)\n",
    "        Gd.add_edge(u,v, weight=w, color=color)\n",
    "    return Gd\n",
    "\n",
    "def analyze_graph(G):\n",
    "    m = {\n",
    "        'num_nodes': G.number_of_nodes(),\n",
    "        'num_edges': G.number_of_edges(),\n",
    "        'avg_edge_weight': (\n",
    "            sum(d['weight'] for _,_,d in G.edges(data=True))\n",
    "            / G.number_of_edges()\n",
    "            if G.number_of_edges() else 0\n",
    "        )\n",
    "    }\n",
    "    comps = list(nx.connected_components(G))\n",
    "    m['num_clusters'] = len(comps)\n",
    "    same = {t:0 for t in KEY_TYPES}\n",
    "    two  = {('Dental','Medical'):0, ('Dental','Technical'):0, ('Medical','Technical'):0}\n",
    "    three = 0\n",
    "    for comp in comps:\n",
    "        types = {G.nodes[n].get('type') for n in comp} & KEY_TYPES\n",
    "        if   len(types)==1:\n",
    "            same[next(iter(types))] += 1\n",
    "        elif len(types)==2:\n",
    "            two[tuple(sorted(types))] += 1\n",
    "        elif types==KEY_TYPES:\n",
    "            three += 1\n",
    "    m['same_color_clusters']  = same\n",
    "    m['two_color_clusters']   = two\n",
    "    m['three_color_clusters'] = three\n",
    "    return pd.Series(m)\n",
    "    \n",
    "# ── 3) Load, Classify, Analyze & Display ──────────────────────────────────────\n",
    "\n",
    "# 3a) Period labels and corresponding HTML files\n",
    "periods   = [\"1946-2003\", \"2004-2013\", \"2014-2018\", \"2019-2021\", \"2022-2023\", \"2024-2026\"]\n",
    "htmls     = [\"Institutions_Network_1946_2003.html\",\n",
    "             \"Institutions_Network_2004_2013.html\",\n",
    "             \"Institutions_Network_2014_2018.html\",\n",
    "             \"Institutions_Network_2019_2021.html\",\n",
    "             \"Institutions_Network_2022_2023.html\",\n",
    "             \"Institutions_Network_2024_2026.html\"]\n",
    "\n",
    "# 3b) Institutions to track\n",
    "track_nodes = [\n",
    "    \"University of California, San Francisco, CA, USA.\",\n",
    "    \"Asociacion Civil Impacta Salud y Educacion, Lima\",\n",
    "    # add more as needed\n",
    "]\n",
    "\n",
    "# 3c) Load & classify all graphs\n",
    "Gs = {}\n",
    "for p, h in zip(periods, htmls):\n",
    "    G = load_pyvis_html(h)\n",
    "    for n in G.nodes():\n",
    "        G.nodes[n]['type'] = classify_institute(n)\n",
    "    Gs[p] = G\n",
    "\n",
    "# 3d) Global metrics table\n",
    "global_df = pd.DataFrame({p: graph_metrics(Gs[p]) for p in periods}).T\n",
    "print(\"=== Global Metrics ===\")\n",
    "display(global_df)\n",
    "\n",
    "# 3e) Top 10 centralities per period\n",
    "# for p in periods:\n",
    "#     print(f\"=== Top 10 Centralities ({p}) ===\")\n",
    "#     display(top_centralities(Gs[p], n=10))\n",
    "\n",
    "# 3f) Overlap & Jaccard for adjacent periods\n",
    "overlap_records = []\n",
    "for p, q in zip(periods, periods[1:]):\n",
    "    n1, n2 = set(Gs[p]), set(Gs[q])\n",
    "    e1, e2 = set(Gs[p].edges()), set(Gs[q].edges())\n",
    "    overlap_records.append({\n",
    "        'from': p, 'to': q,\n",
    "        'node_jaccard':   jaccard(n1, n2),\n",
    "        'edge_jaccard':   jaccard(e1, e2),\n",
    "        'new_nodes':      len(n2 - n1),\n",
    "        'dropped_nodes':  len(n1 - n2),\n",
    "        'new_edges':      len(e2 - e1),\n",
    "        'dropped_edges':  len(e1 - e2),\n",
    "    })\n",
    "overlap_df = pd.DataFrame(overlap_records)\n",
    "print(\"=== Overlap & Jaccard ===\")\n",
    "display(overlap_df)\n",
    "\n",
    "# 3g) Difference graphs pickled\n",
    "for p, q in zip(periods, periods[1:]):\n",
    "    Gd = build_diff_graph(Gs[p], Gs[q])\n",
    "    fn = f\"diff_{p.replace('-','')}_vs_{q.replace('-','')}.gpickle\"\n",
    "    with open(fn, 'wb') as f:\n",
    "        pickle.dump(Gd, f)\n",
    "    print(f\"▶ Pickled difference graph → {fn}\")\n",
    "\n",
    "# 3h) Cluster & color-mix comparison\n",
    "cluster_df = pd.concat({p: analyze_graph(Gs[p]) for p in periods}, axis=1).T\n",
    "print(\"=== Cluster & Color-Mix Comparison ===\")\n",
    "display(cluster_df)\n",
    "\n",
    "# 3i) Centrality trajectories for tracked institutions\n",
    "deg_traj = pd.DataFrame({\n",
    "    p: {node: nx.degree_centrality(Gs[p]).get(node, 0) for node in track_nodes}\n",
    "    for p in periods\n",
    "}).T\n",
    "bet_traj = pd.DataFrame({\n",
    "    p: {node: nx.betweenness_centrality(Gs[p], weight='weight').get(node, 0) for node in track_nodes}\n",
    "    for p in periods\n",
    "}).T\n",
    "\n",
    "print(\"=== Degree Centrality Trajectories ===\")\n",
    "display(deg_traj)\n",
    "print(\"=== Betweenness Centrality Trajectories ===\")\n",
    "display(bet_traj)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "id": "584d18a1-1002-432f-ad1f-601ef1295aac",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Global Metrics ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nodes</th>\n",
       "      <th>edges</th>\n",
       "      <th>density</th>\n",
       "      <th>avg_clustering</th>\n",
       "      <th>largest_cc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946-2003</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-2013</th>\n",
       "      <td>164.0</td>\n",
       "      <td>448.0</td>\n",
       "      <td>0.033518</td>\n",
       "      <td>0.939024</td>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-2018</th>\n",
       "      <td>7494.0</td>\n",
       "      <td>26516.0</td>\n",
       "      <td>0.000944</td>\n",
       "      <td>0.233386</td>\n",
       "      <td>142.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-2021</th>\n",
       "      <td>8658.0</td>\n",
       "      <td>29540.0</td>\n",
       "      <td>0.000788</td>\n",
       "      <td>0.126850</td>\n",
       "      <td>82.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-2023</th>\n",
       "      <td>9273.0</td>\n",
       "      <td>82850.0</td>\n",
       "      <td>0.001927</td>\n",
       "      <td>0.158193</td>\n",
       "      <td>389.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-2026</th>\n",
       "      <td>9690.0</td>\n",
       "      <td>32060.0</td>\n",
       "      <td>0.000683</td>\n",
       "      <td>0.188198</td>\n",
       "      <td>253.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            nodes    edges   density  avg_clustering  largest_cc\n",
       "1946-2003     0.0      0.0  0.000000        0.000000         0.0\n",
       "2004-2013   164.0    448.0  0.033518        0.939024        11.0\n",
       "2014-2018  7494.0  26516.0  0.000944        0.233386       142.0\n",
       "2019-2021  8658.0  29540.0  0.000788        0.126850        82.0\n",
       "2022-2023  9273.0  82850.0  0.001927        0.158193       389.0\n",
       "2024-2026  9690.0  32060.0  0.000683        0.188198       253.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Normalized/Relative Density & Degree ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>density_existing</th>\n",
       "      <th>density_new</th>\n",
       "      <th>avg_degree</th>\n",
       "      <th>edge_growth_per_new</th>\n",
       "      <th>new_nodes</th>\n",
       "      <th>returning_nodes</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946-2003</td>\n",
       "      <td>2004-2013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.033518</td>\n",
       "      <td>5.463415</td>\n",
       "      <td>2.731707</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-2013</td>\n",
       "      <td>2014-2018</td>\n",
       "      <td>0.098901</td>\n",
       "      <td>0.000945</td>\n",
       "      <td>7.076595</td>\n",
       "      <td>3.543717</td>\n",
       "      <td>7480</td>\n",
       "      <td>14</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-2018</td>\n",
       "      <td>2019-2021</td>\n",
       "      <td>0.007261</td>\n",
       "      <td>0.000786</td>\n",
       "      <td>6.823747</td>\n",
       "      <td>3.487622</td>\n",
       "      <td>8402</td>\n",
       "      <td>256</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-2021</td>\n",
       "      <td>2022-2023</td>\n",
       "      <td>0.006565</td>\n",
       "      <td>0.001995</td>\n",
       "      <td>17.869082</td>\n",
       "      <td>9.289456</td>\n",
       "      <td>8858</td>\n",
       "      <td>415</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>2024-2026</td>\n",
       "      <td>0.009592</td>\n",
       "      <td>0.000669</td>\n",
       "      <td>6.617131</td>\n",
       "      <td>3.368772</td>\n",
       "      <td>9293</td>\n",
       "      <td>397</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        from         to  density_existing  density_new  avg_degree  \\\n",
       "0  1946-2003  2004-2013          0.000000     0.033518    5.463415   \n",
       "1  2004-2013  2014-2018          0.098901     0.000945    7.076595   \n",
       "2  2014-2018  2019-2021          0.007261     0.000786    6.823747   \n",
       "3  2019-2021  2022-2023          0.006565     0.001995   17.869082   \n",
       "4  2022-2023  2024-2026          0.009592     0.000669    6.617131   \n",
       "\n",
       "   edge_growth_per_new  new_nodes  returning_nodes  \n",
       "0             2.731707        164                0  \n",
       "1             3.543717       7480               14  \n",
       "2             3.487622       8402              256  \n",
       "3             9.289456       8858              415  \n",
       "4             3.368772       9293              397  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Overlap & Jaccard ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>from</th>\n",
       "      <th>to</th>\n",
       "      <th>node_jaccard</th>\n",
       "      <th>edge_jaccard</th>\n",
       "      <th>new_nodes</th>\n",
       "      <th>dropped_nodes</th>\n",
       "      <th>new_edges</th>\n",
       "      <th>dropped_edges</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1946-2003</td>\n",
       "      <td>2004-2013</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>164</td>\n",
       "      <td>0</td>\n",
       "      <td>448</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2004-2013</td>\n",
       "      <td>2014-2018</td>\n",
       "      <td>0.001832</td>\n",
       "      <td>0.000297</td>\n",
       "      <td>7480</td>\n",
       "      <td>150</td>\n",
       "      <td>26508</td>\n",
       "      <td>440</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2014-2018</td>\n",
       "      <td>2019-2021</td>\n",
       "      <td>0.016105</td>\n",
       "      <td>0.003635</td>\n",
       "      <td>8402</td>\n",
       "      <td>7238</td>\n",
       "      <td>29337</td>\n",
       "      <td>26313</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2019-2021</td>\n",
       "      <td>2022-2023</td>\n",
       "      <td>0.023693</td>\n",
       "      <td>0.004244</td>\n",
       "      <td>8858</td>\n",
       "      <td>8243</td>\n",
       "      <td>82375</td>\n",
       "      <td>29065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2022-2023</td>\n",
       "      <td>2024-2026</td>\n",
       "      <td>0.021383</td>\n",
       "      <td>0.005126</td>\n",
       "      <td>9293</td>\n",
       "      <td>8876</td>\n",
       "      <td>31474</td>\n",
       "      <td>82264</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        from         to  node_jaccard  edge_jaccard  new_nodes  dropped_nodes  \\\n",
       "0  1946-2003  2004-2013      0.000000      0.000000        164              0   \n",
       "1  2004-2013  2014-2018      0.001832      0.000297       7480            150   \n",
       "2  2014-2018  2019-2021      0.016105      0.003635       8402           7238   \n",
       "3  2019-2021  2022-2023      0.023693      0.004244       8858           8243   \n",
       "4  2022-2023  2024-2026      0.021383      0.005126       9293           8876   \n",
       "\n",
       "   new_edges  dropped_edges  \n",
       "0        448              0  \n",
       "1      26508            440  \n",
       "2      29337          26313  \n",
       "3      82375          29065  \n",
       "4      31474          82264  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "▶ Pickled difference graph → diff_19462003_vs_20042013.gpickle\n",
      "▶ Pickled difference graph → diff_20042013_vs_20142018.gpickle\n",
      "▶ Pickled difference graph → diff_20142018_vs_20192021.gpickle\n",
      "▶ Pickled difference graph → diff_20192021_vs_20222023.gpickle\n",
      "▶ Pickled difference graph → diff_20222023_vs_20242026.gpickle\n",
      "=== Cluster & Color-Mix Comparison ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_nodes</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>avg_edge_weight</th>\n",
       "      <th>num_clusters</th>\n",
       "      <th>same_color_clusters</th>\n",
       "      <th>two_color_clusters</th>\n",
       "      <th>three_color_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946-2003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Technical': 0, 'Dental': 0, 'Medical': 0}</td>\n",
       "      <td>{('Dental', 'Medical'): 0, ('Dental', 'Technic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-2013</th>\n",
       "      <td>164</td>\n",
       "      <td>448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>{'Technical': 1, 'Dental': 1, 'Medical': 17}</td>\n",
       "      <td>{('Dental', 'Medical'): 3, ('Dental', 'Technic...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-2018</th>\n",
       "      <td>7494</td>\n",
       "      <td>26516</td>\n",
       "      <td>1.016782</td>\n",
       "      <td>1338</td>\n",
       "      <td>{'Technical': 49, 'Dental': 94, 'Medical': 614}</td>\n",
       "      <td>{('Dental', 'Medical'): 302, ('Dental', 'Techn...</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-2021</th>\n",
       "      <td>8658</td>\n",
       "      <td>29540</td>\n",
       "      <td>1.087204</td>\n",
       "      <td>1509</td>\n",
       "      <td>{'Technical': 80, 'Dental': 135, 'Medical': 596}</td>\n",
       "      <td>{('Dental', 'Medical'): 311, ('Dental', 'Techn...</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-2023</th>\n",
       "      <td>9273</td>\n",
       "      <td>82850</td>\n",
       "      <td>1.007677</td>\n",
       "      <td>1467</td>\n",
       "      <td>{'Technical': 75, 'Dental': 181, 'Medical': 438}</td>\n",
       "      <td>{('Dental', 'Medical'): 304, ('Dental', 'Techn...</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-2026</th>\n",
       "      <td>9690</td>\n",
       "      <td>32060</td>\n",
       "      <td>1.028291</td>\n",
       "      <td>1671</td>\n",
       "      <td>{'Technical': 83, 'Dental': 281, 'Medical': 429}</td>\n",
       "      <td>{('Dental', 'Medical'): 367, ('Dental', 'Techn...</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_nodes num_edges avg_edge_weight num_clusters  \\\n",
       "1946-2003         0         0               0            0   \n",
       "2004-2013       164       448             1.0           33   \n",
       "2014-2018      7494     26516        1.016782         1338   \n",
       "2019-2021      8658     29540        1.087204         1509   \n",
       "2022-2023      9273     82850        1.007677         1467   \n",
       "2024-2026      9690     32060        1.028291         1671   \n",
       "\n",
       "                                        same_color_clusters  \\\n",
       "1946-2003       {'Technical': 0, 'Dental': 0, 'Medical': 0}   \n",
       "2004-2013      {'Technical': 1, 'Dental': 1, 'Medical': 17}   \n",
       "2014-2018   {'Technical': 49, 'Dental': 94, 'Medical': 614}   \n",
       "2019-2021  {'Technical': 80, 'Dental': 135, 'Medical': 596}   \n",
       "2022-2023  {'Technical': 75, 'Dental': 181, 'Medical': 438}   \n",
       "2024-2026  {'Technical': 83, 'Dental': 281, 'Medical': 429}   \n",
       "\n",
       "                                          two_color_clusters  \\\n",
       "1946-2003  {('Dental', 'Medical'): 0, ('Dental', 'Technic...   \n",
       "2004-2013  {('Dental', 'Medical'): 3, ('Dental', 'Technic...   \n",
       "2014-2018  {('Dental', 'Medical'): 302, ('Dental', 'Techn...   \n",
       "2019-2021  {('Dental', 'Medical'): 311, ('Dental', 'Techn...   \n",
       "2022-2023  {('Dental', 'Medical'): 304, ('Dental', 'Techn...   \n",
       "2024-2026  {('Dental', 'Medical'): 367, ('Dental', 'Techn...   \n",
       "\n",
       "          three_color_clusters  \n",
       "1946-2003                    0  \n",
       "2004-2013                    3  \n",
       "2014-2018                   59  \n",
       "2019-2021                  100  \n",
       "2022-2023                  132  \n",
       "2024-2026                  139  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Degree Centrality Trajectories ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University of California, San Francisco, CA, USA.</th>\n",
       "      <th>Asociacion Civil Impacta Salud y Educacion, Lima</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946-2003</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-2013</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-2018</th>\n",
       "      <td>0.004137</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-2021</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-2023</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-2026</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           University of California, San Francisco, CA, USA.  \\\n",
       "1946-2003                                           0.000000   \n",
       "2004-2013                                           0.000000   \n",
       "2014-2018                                           0.004137   \n",
       "2019-2021                                           0.000000   \n",
       "2022-2023                                           0.000000   \n",
       "2024-2026                                           0.000000   \n",
       "\n",
       "           Asociacion Civil Impacta Salud y Educacion, Lima  \n",
       "1946-2003                                               0.0  \n",
       "2004-2013                                               0.0  \n",
       "2014-2018                                               0.0  \n",
       "2019-2021                                               0.0  \n",
       "2022-2023                                               0.0  \n",
       "2024-2026                                               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Betweenness Centrality Trajectories ===\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>University of California, San Francisco, CA, USA.</th>\n",
       "      <th>Asociacion Civil Impacta Salud y Educacion, Lima</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946-2003</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-2013</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-2018</th>\n",
       "      <td>0.000014</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-2021</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-2023</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-2026</th>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           University of California, San Francisco, CA, USA.  \\\n",
       "1946-2003                                           0.000000   \n",
       "2004-2013                                           0.000000   \n",
       "2014-2018                                           0.000014   \n",
       "2019-2021                                           0.000000   \n",
       "2022-2023                                           0.000000   \n",
       "2024-2026                                           0.000000   \n",
       "\n",
       "           Asociacion Civil Impacta Salud y Educacion, Lima  \n",
       "1946-2003                                               0.0  \n",
       "2004-2013                                               0.0  \n",
       "2014-2018                                               0.0  \n",
       "2019-2021                                               0.0  \n",
       "2022-2023                                               0.0  \n",
       "2024-2026                                               0.0  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import re, json, pickle, networkx as nx\n",
    "import pandas as pd\n",
    "\n",
    "# ... (Your load_pyvis_html, classify_institute, etc. as above) ...\n",
    "\n",
    "# ---- NEW: DENSITY & DEGREE METRICS UTILITIES ----\n",
    "def get_density_metrics(G_prev, G_next):\n",
    "    \"\"\"\n",
    "    Calculate various normalized/relative density metrics for two consecutive periods.\n",
    "    Returns a dict with keys:\n",
    "      - density_existing: Density among persistent (intersection) institutions\n",
    "      - density_new: Density among new institutions in this period\n",
    "      - avg_degree: Edges / nodes in current graph\n",
    "      - edge_growth_per_new: New edges / new nodes (to measure integration)\n",
    "    \"\"\"\n",
    "    nodes_prev = set(G_prev.nodes())\n",
    "    nodes_next = set(G_next.nodes())\n",
    "    nodes_both = nodes_prev & nodes_next\n",
    "    nodes_new = nodes_next - nodes_prev\n",
    "\n",
    "    # Density among persistent institutions\n",
    "    if len(nodes_both) > 1:\n",
    "        subG_both = G_next.subgraph(nodes_both)\n",
    "        density_existing = nx.density(subG_both)\n",
    "    else:\n",
    "        density_existing = 0.0\n",
    "\n",
    "    # Density among new institutions\n",
    "    if len(nodes_new) > 1:\n",
    "        subG_new = G_next.subgraph(nodes_new)\n",
    "        density_new = nx.density(subG_new)\n",
    "    else:\n",
    "        density_new = 0.0\n",
    "\n",
    "    # Edge growth per new node\n",
    "    new_edges = [\n",
    "        (u, v) for (u, v) in G_next.edges()\n",
    "        if (u in nodes_new or v in nodes_new)\n",
    "    ]\n",
    "    edge_growth_per_new = len(new_edges) / len(nodes_new) if nodes_new else 0.0\n",
    "\n",
    "    # Average degree (all institutions)\n",
    "    avg_degree = (2 * G_next.number_of_edges() / G_next.number_of_nodes()) if G_next.number_of_nodes() > 0 else 0.0\n",
    "\n",
    "    return {\n",
    "        'density_existing': density_existing,\n",
    "        'density_new': density_new,\n",
    "        'avg_degree': avg_degree,\n",
    "        'edge_growth_per_new': edge_growth_per_new,\n",
    "        'new_nodes': len(nodes_new),\n",
    "        'returning_nodes': len(nodes_both),\n",
    "    }\n",
    "\n",
    "# ---- (rest of your analysis code as before) ----\n",
    "\n",
    "# 3c) Load & classify all graphs\n",
    "Gs = {}\n",
    "for p, h in zip(periods, htmls):\n",
    "    G = load_pyvis_html(h)\n",
    "    for n in G.nodes():\n",
    "        G.nodes[n]['type'] = classify_institute(n)\n",
    "    Gs[p] = G\n",
    "\n",
    "# 3d) Global metrics table\n",
    "global_df = pd.DataFrame({p: graph_metrics(Gs[p]) for p in periods}).T\n",
    "print(\"=== Global Metrics ===\")\n",
    "display(global_df)\n",
    "\n",
    "# ---- NEW: NORMALIZED/RELATIVE DENSITY TABLE ----\n",
    "density_metrics = []\n",
    "for i in range(1, len(periods)):\n",
    "    prev_p, curr_p = periods[i-1], periods[i]\n",
    "    G_prev, G_curr = Gs[prev_p], Gs[curr_p]\n",
    "    met = get_density_metrics(G_prev, G_curr)\n",
    "    met['from'] = prev_p\n",
    "    met['to'] = curr_p\n",
    "    density_metrics.append(met)\n",
    "\n",
    "density_df = pd.DataFrame(density_metrics)\n",
    "print(\"=== Normalized/Relative Density & Degree ===\")\n",
    "display(density_df[['from', 'to', 'density_existing', 'density_new', 'avg_degree', 'edge_growth_per_new', 'new_nodes', 'returning_nodes']])\n",
    "\n",
    "overlap_records = []\n",
    "for p, q in zip(periods, periods[1:]):\n",
    "    n1, n2 = set(Gs[p]), set(Gs[q])\n",
    "    e1, e2 = set(Gs[p].edges()), set(Gs[q].edges())\n",
    "    overlap_records.append({\n",
    "        'from': p, 'to': q,\n",
    "        'node_jaccard':   jaccard(n1, n2),\n",
    "        'edge_jaccard':   jaccard(e1, e2),\n",
    "        'new_nodes':      len(n2 - n1),\n",
    "        'dropped_nodes':  len(n1 - n2),\n",
    "        'new_edges':      len(e2 - e1),\n",
    "        'dropped_edges':  len(e1 - e2),\n",
    "    })\n",
    "overlap_df = pd.DataFrame(overlap_records)\n",
    "print(\"=== Overlap & Jaccard ===\")\n",
    "display(overlap_df)\n",
    "\n",
    "# 3g) Difference graphs pickled\n",
    "for p, q in zip(periods, periods[1:]):\n",
    "    Gd = build_diff_graph(Gs[p], Gs[q])\n",
    "    fn = f\"diff_{p.replace('-','')}_vs_{q.replace('-','')}.gpickle\"\n",
    "    with open(fn, 'wb') as f:\n",
    "        pickle.dump(Gd, f)\n",
    "    print(f\"▶ Pickled difference graph → {fn}\")\n",
    "\n",
    "# 3h) Cluster & color-mix comparison\n",
    "cluster_df = pd.concat({p: analyze_graph(Gs[p]) for p in periods}, axis=1).T\n",
    "print(\"=== Cluster & Color-Mix Comparison ===\")\n",
    "display(cluster_df)\n",
    "\n",
    "# 3i) Centrality trajectories for tracked institutions\n",
    "deg_traj = pd.DataFrame({\n",
    "    p: {node: nx.degree_centrality(Gs[p]).get(node, 0) for node in track_nodes}\n",
    "    for p in periods\n",
    "}).T\n",
    "bet_traj = pd.DataFrame({\n",
    "    p: {node: nx.betweenness_centrality(Gs[p], weight='weight').get(node, 0) for node in track_nodes}\n",
    "    for p in periods\n",
    "}).T\n",
    "\n",
    "print(\"=== Degree Centrality Trajectories ===\")\n",
    "display(deg_traj)\n",
    "print(\"=== Betweenness Centrality Trajectories ===\")\n",
    "display(bet_traj)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 197,
   "id": "61ffae41-4bbd-48d6-b985-42fd59105da7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>num_nodes</th>\n",
       "      <th>num_edges</th>\n",
       "      <th>avg_edge_weight</th>\n",
       "      <th>num_clusters</th>\n",
       "      <th>same_color_clusters</th>\n",
       "      <th>two_color_clusters</th>\n",
       "      <th>three_color_clusters</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1946-2003</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>{'Technical': 0, 'Dental': 0, 'Medical': 0}</td>\n",
       "      <td>{('Dental', 'Medical'): 0, ('Dental', 'Technical'): 0, ('Medical', 'Technical'): 0}</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2004-2013</th>\n",
       "      <td>164</td>\n",
       "      <td>448</td>\n",
       "      <td>1.0</td>\n",
       "      <td>33</td>\n",
       "      <td>{'Technical': 1, 'Dental': 1, 'Medical': 17}</td>\n",
       "      <td>{('Dental', 'Medical'): 3, ('Dental', 'Technical'): 0, ('Medical', 'Technical'): 7}</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2014-2018</th>\n",
       "      <td>7494</td>\n",
       "      <td>26516</td>\n",
       "      <td>1.016782</td>\n",
       "      <td>1338</td>\n",
       "      <td>{'Technical': 49, 'Dental': 94, 'Medical': 614}</td>\n",
       "      <td>{('Dental', 'Medical'): 302, ('Dental', 'Technical'): 45, ('Medical', 'Technical'): 117}</td>\n",
       "      <td>59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2019-2021</th>\n",
       "      <td>8658</td>\n",
       "      <td>29540</td>\n",
       "      <td>1.087204</td>\n",
       "      <td>1509</td>\n",
       "      <td>{'Technical': 80, 'Dental': 135, 'Medical': 596}</td>\n",
       "      <td>{('Dental', 'Medical'): 311, ('Dental', 'Technical'): 71, ('Medical', 'Technical'): 161}</td>\n",
       "      <td>100</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2022-2023</th>\n",
       "      <td>9273</td>\n",
       "      <td>82850</td>\n",
       "      <td>1.007677</td>\n",
       "      <td>1467</td>\n",
       "      <td>{'Technical': 75, 'Dental': 181, 'Medical': 438}</td>\n",
       "      <td>{('Dental', 'Medical'): 304, ('Dental', 'Technical'): 109, ('Medical', 'Technical'): 180}</td>\n",
       "      <td>132</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2024-2026</th>\n",
       "      <td>9690</td>\n",
       "      <td>32060</td>\n",
       "      <td>1.028291</td>\n",
       "      <td>1671</td>\n",
       "      <td>{'Technical': 83, 'Dental': 281, 'Medical': 429}</td>\n",
       "      <td>{('Dental', 'Medical'): 367, ('Dental', 'Technical'): 141, ('Medical', 'Technical'): 160}</td>\n",
       "      <td>139</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "          num_nodes num_edges avg_edge_weight num_clusters  \\\n",
       "1946-2003         0         0               0            0   \n",
       "2004-2013       164       448             1.0           33   \n",
       "2014-2018      7494     26516        1.016782         1338   \n",
       "2019-2021      8658     29540        1.087204         1509   \n",
       "2022-2023      9273     82850        1.007677         1467   \n",
       "2024-2026      9690     32060        1.028291         1671   \n",
       "\n",
       "                                        same_color_clusters  \\\n",
       "1946-2003       {'Technical': 0, 'Dental': 0, 'Medical': 0}   \n",
       "2004-2013      {'Technical': 1, 'Dental': 1, 'Medical': 17}   \n",
       "2014-2018   {'Technical': 49, 'Dental': 94, 'Medical': 614}   \n",
       "2019-2021  {'Technical': 80, 'Dental': 135, 'Medical': 596}   \n",
       "2022-2023  {'Technical': 75, 'Dental': 181, 'Medical': 438}   \n",
       "2024-2026  {'Technical': 83, 'Dental': 281, 'Medical': 429}   \n",
       "\n",
       "                                                                                  two_color_clusters  \\\n",
       "1946-2003        {('Dental', 'Medical'): 0, ('Dental', 'Technical'): 0, ('Medical', 'Technical'): 0}   \n",
       "2004-2013        {('Dental', 'Medical'): 3, ('Dental', 'Technical'): 0, ('Medical', 'Technical'): 7}   \n",
       "2014-2018   {('Dental', 'Medical'): 302, ('Dental', 'Technical'): 45, ('Medical', 'Technical'): 117}   \n",
       "2019-2021   {('Dental', 'Medical'): 311, ('Dental', 'Technical'): 71, ('Medical', 'Technical'): 161}   \n",
       "2022-2023  {('Dental', 'Medical'): 304, ('Dental', 'Technical'): 109, ('Medical', 'Technical'): 180}   \n",
       "2024-2026  {('Dental', 'Medical'): 367, ('Dental', 'Technical'): 141, ('Medical', 'Technical'): 160}   \n",
       "\n",
       "          three_color_clusters  \n",
       "1946-2003                    0  \n",
       "2004-2013                    3  \n",
       "2014-2018                   59  \n",
       "2019-2021                  100  \n",
       "2022-2023                  132  \n",
       "2024-2026                  139  "
      ]
     },
     "execution_count": 197,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.set_option(\"max_colwidth\", None)\n",
    "cluster_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "id": "1ef86e50-f1b0-47bc-93c6-12bb2772c93a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>periods_present</th>\n",
       "      <th>institution_count</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>32719</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1068</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>120</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>16</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   periods_present  institution_count\n",
       "0                1              32719\n",
       "1                2               1068\n",
       "2                3                120\n",
       "3                4                 16"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32719 institutions appeared in only one period; 0 appeared in all 6 periods.\n"
     ]
    }
   ],
   "source": [
    "# ── Additional Analysis: Single-vs-Constant Players (robust) ───────────────────\n",
    "\n",
    "# 1) Ensure Gs is already defined, mapping each period to its NetworkX graph\n",
    "\n",
    "# 2) Count in how many periods each institution appears\n",
    "appearance_counts = {}\n",
    "for period, graph in Gs.items():\n",
    "    for inst in graph.nodes():\n",
    "        appearance_counts[inst] = appearance_counts.get(inst, 0) + 1\n",
    "\n",
    "# 3) Build a distribution of “periods_present” → institution_count\n",
    "import pandas as pd\n",
    "ap_df = pd.Series(appearance_counts, name=\"periods_present\")\n",
    "dist = (\n",
    "    ap_df\n",
    "    .value_counts()\n",
    "    .sort_index()\n",
    "    .rename_axis(\"periods_present\")\n",
    "    .reset_index(name=\"institution_count\")\n",
    ")\n",
    "display(dist)\n",
    "\n",
    "# 4) Safely pull out the two key numbers (default to 0 if missing)\n",
    "single_row = dist.loc[dist.periods_present == 1, \"institution_count\"]\n",
    "single = int(single_row.iloc[0]) if not single_row.empty else 0\n",
    "\n",
    "constant_row = dist.loc[dist.periods_present == len(periods), \"institution_count\"]\n",
    "constant = int(constant_row.iloc[0]) if not constant_row.empty else 0\n",
    "\n",
    "print(f\"{single} institutions appeared in only one period; {constant} appeared in all {len(periods)} periods.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "id": "8f42c4fe-614c-425f-bbc8-beacea486da0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of publications that contain the term University of Texas Health Science Center at Houston AND (\"systematic review\"[Publication Type] OR \"meta analysis\"[Publication Type] OR \"network meta analysis\"[Publication Type]): 1642\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████| 17/17 [00:25<00:00,  1.51s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Complete.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nxviz\n",
    "import difflib\n",
    "import pandas as pd\n",
    "from tqdm import tqdm\n",
    "import networkx as nx\n",
    "from Bio import Entrez\n",
    "from Bio import Medline\n",
    "from dateutil import parser\n",
    "from iso3166 import countries\n",
    "import pycountry_convert as pc\n",
    "import country_converter as coco\n",
    "from itertools import combinations\n",
    "import gender_guesser.detector as gender\n",
    "\n",
    "\n",
    "# Change this email to your email address\n",
    "Entrez.email = \"pratapsingh@1102@gmail.com\"\n",
    "\n",
    "keyword = \"\"\"University of Texas Health Science Center at Houston AND (\"systematic review\"[Publication Type] OR \"meta analysis\"[Publication Type] OR \"network meta analysis\"[Publication Type])\"\"\"\n",
    "\n",
    "result = Entrez.read(Entrez.esearch(db=\"pubmed\", retmax=10, term=keyword))\n",
    "print(\n",
    "    \"Total number of publications that contain the term {}: {}\".format(\n",
    "        keyword, result[\"Count\"]\n",
    "    )\n",
    ")\n",
    "\n",
    "# Fetch all ids\n",
    "MAX_COUNT = result[\"Count\"]\n",
    "result = Entrez.read(\n",
    "    Entrez.esearch(db=\"pubmed\", retmax=result[\"Count\"], term=keyword)\n",
    ")\n",
    "\n",
    "ids = result[\"IdList\"]\n",
    "\n",
    "batch_size = 100\n",
    "batches = [ids[x: x + 100] for x in range(0, len(ids), batch_size)]\n",
    "\n",
    "record_list = []\n",
    "for batch in tqdm(batches):\n",
    "    h = Entrez.efetch(db=\"pubmed\", id=batch, rettype=\"medline\", retmode=\"text\")\n",
    "    records = Medline.parse(h)\n",
    "    record_list.extend(list(records))\n",
    "print(\"Complete.\")\n",
    "\n",
    "from collections import Counter\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "\n",
    "sns.set_style(\"white\")\n",
    "\n",
    "publication_data = pd.DataFrame(record_list)\n",
    "publication_data. rename(columns = {'AB':'Abstract', 'CI':'Copyright Information',\n",
    "                     'AD':'Affiliation', 'IRAD':'Investigator Affiliation',\n",
    "                     'AU':'Author', 'FAU':'Full Author',\n",
    "                      'COIS':'Conflict of Interest Statement', 'CRDT':'Create Date',\n",
    "                      'DEP':'Date of Electronic Publication', 'DP':'Date of Publication',\n",
    "                      'EN':'Edition', 'ED':'Editor',\n",
    "                      'GN':'General Note', 'FIR':'Full Investigator Name',\n",
    "                      'JT':'Journal Title', 'RF':'Number of References',\n",
    "                      'PL':'Place of Publication', 'PST':'Publication Status',\n",
    "                      'PT':'Publication Type', 'PUBM':'Publication Model',\n",
    "                      'NM':'Substance Name', 'TI':'Title', 'LID':'Location Identifier',\n",
    "                      'PMID':'PubMed Unique Identifier', 'OWN':'Owner', 'STAT':'Status', 'LR':'Date Last Revised', 'IS':'ISSN', \n",
    "                      'VI':'Volume', 'IP':'Issue', 'PG':'Pagination',\n",
    "                      'LA':'Language', 'TA': 'Journal Title Abbreviation', 'JID': 'NLM Unique ID', \n",
    "                      'PMC':'PubMed Central Identifier', 'OTO':'Other Term Owner','OT':'Other Term', 'EDAT':'Entrez Date', \n",
    "                      'MHDA':'MeSH Date', 'PHST':'Publication History Status', 'AID':'Article Identifier', 'SO':'Source', \n",
    "                      'AUID':'Author Identifier', 'GR':'Grant Number', 'SB':'Subset', 'SI': 'Secondary Source ID',\n",
    "                      'DCOM':'Date Completed', 'RN': 'Registry Number/EC Number', 'MH': 'MeSH Terms', 'BTI':'Book Title', \n",
    "                      'PMCR':'PubMed Central Release', 'FED':'Editor and Full Editor Name',\n",
    "                      'CN':'Corporate Author', 'MID':'Manuscript Identifier', \n",
    "                      'IR':'Investigator name and Full Investigator Name'\n",
    "                      }, inplace = True)\n",
    "\n",
    "\n",
    "publication_data['keyword'] = keyword"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "id": "702246a2-fdc9-4de7-92bf-6d7f2e4d5807",
   "metadata": {},
   "outputs": [],
   "source": [
    "e = publication_data.copy()\n",
    "e['Date Last Revised']= pd.to_datetime(e['Date Last Revised'])\n",
    "e['Entrez Date']= pd.to_datetime(e['Entrez Date'])\n",
    "e['Date Completed']= pd.to_datetime(e['Date Completed'])\n",
    "# e['Date of Publication']= pd.to_datetime(e['Date of Publication'])\n",
    "e['Date of Electronic Publication']= pd.to_datetime(e['Date of Electronic Publication'])\n",
    "def approximate_date(date_str):\n",
    "    if pd.isnull(date_str):\n",
    "        return pd.NaT\n",
    "    s = str(date_str)\n",
    "    # Replace a month range \"Jan-Mar\" with just \"Jan\"\n",
    "    s = re.sub(r'([A-Za-z]{3,9})-[A-Za-z]{3,9}', r'\\1', s)\n",
    "    # If only a year, append Jan\n",
    "    if re.fullmatch(r'\\d{4}', s):\n",
    "        s += \" Jan\"\n",
    "    try:\n",
    "        return parser.parse(s, default=parser.parse(\"1900-01-01\"))\n",
    "    except Exception:\n",
    "        return pd.NaT\n",
    "\n",
    "e['Date of Publication'] = e['Date of Publication'].apply(approximate_date)\n",
    "e['Publication Year'] = pd.DatetimeIndex(e['Date of Publication']).year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "id": "9ea29833-1f54-4ca7-b813-3c4bc7e970a2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['PubMed Unique Identifier', 'Owner', 'Status', 'Date Completed',\n",
       "       'Date Last Revised', 'ISSN', 'Volume', 'Issue', 'Date of Publication',\n",
       "       'Title', 'Pagination', 'Location Identifier', 'Abstract',\n",
       "       'Copyright Information', 'Full Author', 'Author', 'Author Identifier',\n",
       "       'Affiliation', 'Language', 'Grant Number', 'Publication Type',\n",
       "       'Date of Electronic Publication', 'Place of Publication',\n",
       "       'Journal Title Abbreviation', 'Journal Title', 'NLM Unique ID',\n",
       "       'Subset', 'MeSH Terms', 'PubMed Central Identifier',\n",
       "       'Conflict of Interest Statement', 'Entrez Date', 'MeSH Date',\n",
       "       'PubMed Central Release', 'Create Date', 'Publication History Status',\n",
       "       'Article Identifier', 'Publication Status', 'Source',\n",
       "       'Other Term Owner', 'Other Term', 'Corporate Author',\n",
       "       'Registry Number/EC Number', 'Full Investigator Name',\n",
       "       'Investigator name and Full Investigator Name', 'OAB', 'OABL',\n",
       "       'Manuscript Identifier', 'Investigator Affiliation', 'CIN',\n",
       "       'Secondary Source ID', 'UOF', 'EIN', 'TT', 'OID',\n",
       "       'Number of References', 'General Note', 'keyword', 'Publication Year'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 205,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "id": "b511841d-e816-44ff-b432-4dc60d885c9a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(612, 58)"
      ]
     },
     "execution_count": 210,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "e.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "id": "72c18b84-9eea-45d2-9408-2e9b589ea29b",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[212], line 58\u001b[0m\n\u001b[1;32m     56\u001b[0m \u001b[38;5;66;03m# Add edges with thickness based on co-publication count\u001b[39;00m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m _, row \u001b[38;5;129;01min\u001b[39;00m edge_df\u001b[38;5;241m.\u001b[39miterrows():\n\u001b[0;32m---> 58\u001b[0m     \u001b[43mnet\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43madd_edge\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     59\u001b[0m \u001b[43m        \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mSource\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mTarget\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     61\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtitle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mCo-publications: \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mrow\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mWeight\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m\"\u001b[39;49m\n\u001b[1;32m     62\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;66;03m# Write out and report\u001b[39;00m\n\u001b[1;32m     65\u001b[0m filename \u001b[38;5;241m=\u001b[39m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mAuthors_Network_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mSTART\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mEND\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.html\u001b[39m\u001b[38;5;124m\"\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.12/site-packages/pyvis/network.py:382\u001b[0m, in \u001b[0;36mNetwork.add_edge\u001b[0;34m(self, source, to, **options)\u001b[0m\n\u001b[1;32m    378\u001b[0m         frm \u001b[38;5;241m=\u001b[39m e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfrom\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    379\u001b[0m         dest \u001b[38;5;241m=\u001b[39m e[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mto\u001b[39m\u001b[38;5;124m'\u001b[39m]\n\u001b[1;32m    380\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    381\u001b[0m                 (source \u001b[38;5;241m==\u001b[39m dest \u001b[38;5;129;01mand\u001b[39;00m to \u001b[38;5;241m==\u001b[39m frm) \u001b[38;5;129;01mor\u001b[39;00m\n\u001b[0;32m--> 382\u001b[0m                 (source \u001b[38;5;241m==\u001b[39m frm \u001b[38;5;129;01mand\u001b[39;00m to \u001b[38;5;241m==\u001b[39m dest)\n\u001b[1;32m    383\u001b[0m         ):\n\u001b[1;32m    384\u001b[0m             \u001b[38;5;66;03m# edge already exists\u001b[39;00m\n\u001b[1;32m    385\u001b[0m             edge_exists \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    387\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m edge_exists:\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from itertools import combinations\n",
    "from collections import Counter\n",
    "from pyvis.network import Network\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "START, END = 2020, 2026\n",
    "\n",
    "# --- FILTER TO MOST RECENT PERIOD & MULTI-AUTHOR PAPERS ---\n",
    "# Assume e is your DataFrame and \"Authors\" is a list of author names per paper\n",
    "mask = (\n",
    "    e['Publication Year'].between(START, END)\n",
    "    & e['Full Author'].apply(lambda lst: isinstance(lst, list) and len(lst) > 1)\n",
    ")\n",
    "papers = e.loc[mask, 'Full Author']\n",
    "\n",
    "# --- BUILD CO-AUTHOR EDGES ---\n",
    "edges = []\n",
    "for author_list in papers:\n",
    "    # Remove duplicates within one paper\n",
    "    unique_authors = list(dict.fromkeys(author_list))\n",
    "    edges += combinations(unique_authors, 2)\n",
    "\n",
    "# Count how many papers each pair shares\n",
    "edge_counts = Counter(edges)\n",
    "edge_df = pd.DataFrame(\n",
    "    [(a, b, w) for (a, b), w in edge_counts.items()],\n",
    "    columns=['Source', 'Target', 'Weight']\n",
    ")\n",
    "\n",
    "# --- RENDER WITH PyVis ---\n",
    "net = Network(\n",
    "    height='100vh', width='100vw',\n",
    "    bgcolor='#222222', font_color='white',\n",
    "    directed=False\n",
    ")\n",
    "net.set_options(\"\"\"\n",
    "var options = {\n",
    "  \"nodes\": {\"font\": {\"size\":20, \"color\":\"white\"}},\n",
    "  \"edges\": {\"color\":{\"color\":\"gray\"}, \"width\":2, \"smooth\":false},\n",
    "  \"interaction\": {\"hover\":true, \"tooltipDelay\":50},\n",
    "  \"physics\": {\"barnesHut\": {\"gravitationalConstant\": -20000, \"springLength\":250}}\n",
    "}\n",
    "\"\"\")\n",
    "\n",
    "# Add each author as a node\n",
    "all_authors = set(edge_df['Source']) | set(edge_df['Target'])\n",
    "for author in all_authors:\n",
    "    net.add_node(\n",
    "        author,\n",
    "        label=author,\n",
    "        title=f\"<b>Author:</b> {author}\"\n",
    "        # no color parameter → default styling\n",
    "    )\n",
    "\n",
    "# Add edges with thickness based on co-publication count\n",
    "for _, row in edge_df.iterrows():\n",
    "    net.add_edge(\n",
    "        row['Source'], row['Target'],\n",
    "        value=row['Weight'],\n",
    "        title=f\"Co-publications: {row['Weight']}\"\n",
    "    )\n",
    "\n",
    "# Write out and report\n",
    "filename = f\"Authors_Network_{START}_{END}.html\"\n",
    "net.write_html(filename)\n",
    "print(f\"▶ Saved: {filename}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "id": "c31c2e68-8c40-449c-a9c2-892029352116",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>PublicationCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fornage, Myriam</td>\n",
       "      <td>38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Psaty, Bruce M</td>\n",
       "      <td>31</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Rotter, Jerome I</td>\n",
       "      <td>29</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Boerwinkle, Eric</td>\n",
       "      <td>22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bis, Joshua C</td>\n",
       "      <td>21</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15251</th>\n",
       "      <td>Weber-Lassalle, Nana</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15252</th>\n",
       "      <td>Wiesmuller, Lisa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15253</th>\n",
       "      <td>Winham, Stacey</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15254</th>\n",
       "      <td>Yadav, Siddhartha</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15255</th>\n",
       "      <td>Resta, Nicoletta</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>15256 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Author  PublicationCount\n",
       "0           Fornage, Myriam                38\n",
       "1            Psaty, Bruce M                31\n",
       "2          Rotter, Jerome I                29\n",
       "3          Boerwinkle, Eric                22\n",
       "4             Bis, Joshua C                21\n",
       "...                     ...               ...\n",
       "15251  Weber-Lassalle, Nana                 1\n",
       "15252      Wiesmuller, Lisa                 1\n",
       "15253        Winham, Stacey                 1\n",
       "15254     Yadav, Siddhartha                 1\n",
       "15255      Resta, Nicoletta                 1\n",
       "\n",
       "[15256 rows x 2 columns]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from collections import Counter\n",
    "from itertools import chain\n",
    "\n",
    "# --- CONFIGURATION ---\n",
    "START, END = 2020, 2026\n",
    "\n",
    "# --- FILTER TO YOUR PERIOD & MULTI-AUTHOR PAPERS ---\n",
    "mask = (\n",
    "    e['Publication Year'].between(START, END)\n",
    "    & e['Full Author'].apply(lambda lst: isinstance(lst, list) and len(lst) > 0)\n",
    ")\n",
    "author_lists = e.loc[mask, 'Full Author']\n",
    "\n",
    "# --- FLATTEN & COUNT ---\n",
    "# chain.from_iterable will turn [[A, B], [A, C, D], …] into [A, B, A, C, D, …]\n",
    "all_authors = list(chain.from_iterable(author_lists))\n",
    "author_counts = Counter(all_authors)\n",
    "\n",
    "# --- BUILD TABLE ---\n",
    "author_pub_df = (\n",
    "    pd.DataFrame.from_records(\n",
    "        list(author_counts.items()),\n",
    "        columns=['Author', 'PublicationCount']\n",
    "    )\n",
    "    .sort_values('PublicationCount', ascending=False)\n",
    "    .reset_index(drop=True)\n",
    ")\n",
    "\n",
    "author_pub_df\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "ea50eb7e-166e-4a93-83d3-6444842dee64",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>PublicationCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>11226</th>\n",
       "      <td>Sessler, Daniel I</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  Author  PublicationCount\n",
       "11226  Sessler, Daniel I                 1"
      ]
     },
     "execution_count": 251,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessler_row = author_pub_df[\n",
    "    author_pub_df['Author'].str.contains('Sessler, Daniel I', case=False, na=False)\n",
    "]\n",
    "sessler_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "113c7f88-2e4c-4d84-9950-a96adc1215c2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Author</th>\n",
       "      <th>PublicationCount</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>14231</th>\n",
       "      <td>Vargas, Victor</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14559</th>\n",
       "      <td>Florez-Vargas, Oscar</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Author  PublicationCount\n",
       "14231        Vargas, Victor                 1\n",
       "14559  Florez-Vargas, Oscar                 1"
      ]
     },
     "execution_count": 254,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sessler_row = author_pub_df[\n",
    "    author_pub_df['Author'].str.contains('Vargas', case=False, na=False)\n",
    "]\n",
    "sessler_row"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "2d082230-2604-4708-b22d-3c07d15cac83",
   "metadata": {},
   "outputs": [],
   "source": [
    "author_pub_df.to_csv('Authors that published systematic reviews in collaboration with UTHealth Houston.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60412d2-a2b2-43b7-9050-53ecfc703840",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
